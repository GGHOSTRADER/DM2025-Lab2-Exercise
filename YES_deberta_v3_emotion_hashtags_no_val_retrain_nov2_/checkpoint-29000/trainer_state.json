{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.843828294638383,
  "eval_steps": 500,
  "global_step": 29000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.016702856188408218,
      "grad_norm": 7.399198055267334,
      "learning_rate": 9.966594287623184e-06,
      "loss": 1.4494,
      "step": 100
    },
    {
      "epoch": 0.033405712376816436,
      "grad_norm": 6.373987674713135,
      "learning_rate": 9.933188575246367e-06,
      "loss": 1.2871,
      "step": 200
    },
    {
      "epoch": 0.05010856856522465,
      "grad_norm": 15.813668251037598,
      "learning_rate": 9.899782862869552e-06,
      "loss": 1.1648,
      "step": 300
    },
    {
      "epoch": 0.06681142475363287,
      "grad_norm": 13.638374328613281,
      "learning_rate": 9.866377150492735e-06,
      "loss": 1.2101,
      "step": 400
    },
    {
      "epoch": 0.0835142809420411,
      "grad_norm": 7.342842102050781,
      "learning_rate": 9.83297143811592e-06,
      "loss": 1.1603,
      "step": 500
    },
    {
      "epoch": 0.1002171371304493,
      "grad_norm": 12.112373352050781,
      "learning_rate": 9.799565725739103e-06,
      "loss": 1.1351,
      "step": 600
    },
    {
      "epoch": 0.11691999331885752,
      "grad_norm": 12.305154800415039,
      "learning_rate": 9.766160013362286e-06,
      "loss": 1.1228,
      "step": 700
    },
    {
      "epoch": 0.13362284950726575,
      "grad_norm": 8.268508911132812,
      "learning_rate": 9.73275430098547e-06,
      "loss": 1.0916,
      "step": 800
    },
    {
      "epoch": 0.15032570569567397,
      "grad_norm": 10.410360336303711,
      "learning_rate": 9.699348588608652e-06,
      "loss": 1.0094,
      "step": 900
    },
    {
      "epoch": 0.1670285618840822,
      "grad_norm": 5.888035774230957,
      "learning_rate": 9.665942876231836e-06,
      "loss": 0.9854,
      "step": 1000
    },
    {
      "epoch": 0.18373141807249038,
      "grad_norm": 15.399942398071289,
      "learning_rate": 9.63253716385502e-06,
      "loss": 0.9616,
      "step": 1100
    },
    {
      "epoch": 0.2004342742608986,
      "grad_norm": 7.051200866699219,
      "learning_rate": 9.599131451478203e-06,
      "loss": 1.0404,
      "step": 1200
    },
    {
      "epoch": 0.21713713044930683,
      "grad_norm": 7.561476230621338,
      "learning_rate": 9.565725739101387e-06,
      "loss": 1.0178,
      "step": 1300
    },
    {
      "epoch": 0.23383998663771505,
      "grad_norm": 11.888001441955566,
      "learning_rate": 9.53232002672457e-06,
      "loss": 1.0202,
      "step": 1400
    },
    {
      "epoch": 0.25054284282612327,
      "grad_norm": 11.298383712768555,
      "learning_rate": 9.498914314347755e-06,
      "loss": 1.0045,
      "step": 1500
    },
    {
      "epoch": 0.2672456990145315,
      "grad_norm": 16.570903778076172,
      "learning_rate": 9.465508601970938e-06,
      "loss": 0.9374,
      "step": 1600
    },
    {
      "epoch": 0.2839485552029397,
      "grad_norm": 10.580461502075195,
      "learning_rate": 9.432102889594121e-06,
      "loss": 0.942,
      "step": 1700
    },
    {
      "epoch": 0.30065141139134793,
      "grad_norm": 6.848047733306885,
      "learning_rate": 9.398697177217306e-06,
      "loss": 0.9229,
      "step": 1800
    },
    {
      "epoch": 0.31735426757975616,
      "grad_norm": 18.349117279052734,
      "learning_rate": 9.365291464840487e-06,
      "loss": 0.9682,
      "step": 1900
    },
    {
      "epoch": 0.3340571237681644,
      "grad_norm": 14.471426963806152,
      "learning_rate": 9.331885752463672e-06,
      "loss": 0.8979,
      "step": 2000
    },
    {
      "epoch": 0.3507599799565726,
      "grad_norm": 11.594148635864258,
      "learning_rate": 9.298480040086855e-06,
      "loss": 0.9726,
      "step": 2100
    },
    {
      "epoch": 0.36746283614498076,
      "grad_norm": 13.456197738647461,
      "learning_rate": 9.26507432771004e-06,
      "loss": 0.9868,
      "step": 2200
    },
    {
      "epoch": 0.384165692333389,
      "grad_norm": 11.369977951049805,
      "learning_rate": 9.231668615333223e-06,
      "loss": 0.9974,
      "step": 2300
    },
    {
      "epoch": 0.4008685485217972,
      "grad_norm": 7.041738510131836,
      "learning_rate": 9.198262902956406e-06,
      "loss": 1.0287,
      "step": 2400
    },
    {
      "epoch": 0.41757140471020543,
      "grad_norm": 11.056138038635254,
      "learning_rate": 9.16485719057959e-06,
      "loss": 0.9537,
      "step": 2500
    },
    {
      "epoch": 0.43427426089861365,
      "grad_norm": 2.2307040691375732,
      "learning_rate": 9.131451478202772e-06,
      "loss": 0.8747,
      "step": 2600
    },
    {
      "epoch": 0.4509771170870219,
      "grad_norm": 15.44357967376709,
      "learning_rate": 9.098045765825957e-06,
      "loss": 0.9224,
      "step": 2700
    },
    {
      "epoch": 0.4676799732754301,
      "grad_norm": 11.161252975463867,
      "learning_rate": 9.06464005344914e-06,
      "loss": 0.9867,
      "step": 2800
    },
    {
      "epoch": 0.4843828294638383,
      "grad_norm": 9.893027305603027,
      "learning_rate": 9.031234341072323e-06,
      "loss": 0.9564,
      "step": 2900
    },
    {
      "epoch": 0.5010856856522465,
      "grad_norm": 6.260166168212891,
      "learning_rate": 8.997828628695508e-06,
      "loss": 0.9369,
      "step": 3000
    },
    {
      "epoch": 0.5177885418406547,
      "grad_norm": 5.973299503326416,
      "learning_rate": 8.964422916318691e-06,
      "loss": 0.9061,
      "step": 3100
    },
    {
      "epoch": 0.534491398029063,
      "grad_norm": 8.410514831542969,
      "learning_rate": 8.931017203941876e-06,
      "loss": 0.9341,
      "step": 3200
    },
    {
      "epoch": 0.5511942542174711,
      "grad_norm": 7.759857177734375,
      "learning_rate": 8.897611491565059e-06,
      "loss": 0.9721,
      "step": 3300
    },
    {
      "epoch": 0.5678971104058794,
      "grad_norm": 8.558128356933594,
      "learning_rate": 8.864205779188242e-06,
      "loss": 0.9012,
      "step": 3400
    },
    {
      "epoch": 0.5845999665942876,
      "grad_norm": 6.629172325134277,
      "learning_rate": 8.830800066811426e-06,
      "loss": 0.9261,
      "step": 3500
    },
    {
      "epoch": 0.6013028227826959,
      "grad_norm": 9.265106201171875,
      "learning_rate": 8.797394354434608e-06,
      "loss": 0.8921,
      "step": 3600
    },
    {
      "epoch": 0.618005678971104,
      "grad_norm": 7.518377780914307,
      "learning_rate": 8.763988642057793e-06,
      "loss": 0.8616,
      "step": 3700
    },
    {
      "epoch": 0.6347085351595123,
      "grad_norm": 6.192192554473877,
      "learning_rate": 8.730582929680976e-06,
      "loss": 0.8848,
      "step": 3800
    },
    {
      "epoch": 0.6514113913479205,
      "grad_norm": 11.298727989196777,
      "learning_rate": 8.69717721730416e-06,
      "loss": 0.9713,
      "step": 3900
    },
    {
      "epoch": 0.6681142475363288,
      "grad_norm": 4.794539928436279,
      "learning_rate": 8.663771504927343e-06,
      "loss": 0.8733,
      "step": 4000
    },
    {
      "epoch": 0.6848171037247369,
      "grad_norm": 11.39564323425293,
      "learning_rate": 8.630365792550527e-06,
      "loss": 0.9616,
      "step": 4100
    },
    {
      "epoch": 0.7015199599131452,
      "grad_norm": 6.7193193435668945,
      "learning_rate": 8.596960080173711e-06,
      "loss": 0.9499,
      "step": 4200
    },
    {
      "epoch": 0.7182228161015534,
      "grad_norm": 8.286221504211426,
      "learning_rate": 8.563554367796894e-06,
      "loss": 0.9035,
      "step": 4300
    },
    {
      "epoch": 0.7349256722899615,
      "grad_norm": 13.900978088378906,
      "learning_rate": 8.530148655420077e-06,
      "loss": 0.8689,
      "step": 4400
    },
    {
      "epoch": 0.7516285284783698,
      "grad_norm": 13.736953735351562,
      "learning_rate": 8.496742943043262e-06,
      "loss": 0.9562,
      "step": 4500
    },
    {
      "epoch": 0.768331384666778,
      "grad_norm": 7.834003448486328,
      "learning_rate": 8.463337230666445e-06,
      "loss": 0.922,
      "step": 4600
    },
    {
      "epoch": 0.7850342408551862,
      "grad_norm": 7.309656620025635,
      "learning_rate": 8.429931518289628e-06,
      "loss": 0.9338,
      "step": 4700
    },
    {
      "epoch": 0.8017370970435944,
      "grad_norm": 6.976800918579102,
      "learning_rate": 8.396525805912811e-06,
      "loss": 0.8222,
      "step": 4800
    },
    {
      "epoch": 0.8184399532320027,
      "grad_norm": 6.339584827423096,
      "learning_rate": 8.363120093535996e-06,
      "loss": 0.9517,
      "step": 4900
    },
    {
      "epoch": 0.8351428094204109,
      "grad_norm": 8.44631576538086,
      "learning_rate": 8.329714381159179e-06,
      "loss": 0.8575,
      "step": 5000
    },
    {
      "epoch": 0.8518456656088191,
      "grad_norm": 10.164630889892578,
      "learning_rate": 8.296308668782362e-06,
      "loss": 0.9266,
      "step": 5100
    },
    {
      "epoch": 0.8685485217972273,
      "grad_norm": 9.681822776794434,
      "learning_rate": 8.262902956405547e-06,
      "loss": 0.8769,
      "step": 5200
    },
    {
      "epoch": 0.8852513779856356,
      "grad_norm": 10.699201583862305,
      "learning_rate": 8.229497244028728e-06,
      "loss": 0.9415,
      "step": 5300
    },
    {
      "epoch": 0.9019542341740437,
      "grad_norm": 4.948060512542725,
      "learning_rate": 8.196091531651913e-06,
      "loss": 0.8798,
      "step": 5400
    },
    {
      "epoch": 0.918657090362452,
      "grad_norm": 5.810293674468994,
      "learning_rate": 8.162685819275096e-06,
      "loss": 0.9122,
      "step": 5500
    },
    {
      "epoch": 0.9353599465508602,
      "grad_norm": 9.642989158630371,
      "learning_rate": 8.129280106898281e-06,
      "loss": 0.8963,
      "step": 5600
    },
    {
      "epoch": 0.9520628027392685,
      "grad_norm": 11.71157169342041,
      "learning_rate": 8.095874394521464e-06,
      "loss": 0.8891,
      "step": 5700
    },
    {
      "epoch": 0.9687656589276766,
      "grad_norm": 11.198721885681152,
      "learning_rate": 8.062468682144647e-06,
      "loss": 0.9028,
      "step": 5800
    },
    {
      "epoch": 0.9854685151160848,
      "grad_norm": 13.974751472473145,
      "learning_rate": 8.029062969767832e-06,
      "loss": 0.8791,
      "step": 5900
    },
    {
      "epoch": 1.002171371304493,
      "grad_norm": 9.40556526184082,
      "learning_rate": 7.995657257391015e-06,
      "loss": 0.8476,
      "step": 6000
    },
    {
      "epoch": 1.0188742274929012,
      "grad_norm": 10.060968399047852,
      "learning_rate": 7.962251545014198e-06,
      "loss": 0.7851,
      "step": 6100
    },
    {
      "epoch": 1.0355770836813094,
      "grad_norm": 6.455089092254639,
      "learning_rate": 7.928845832637383e-06,
      "loss": 0.8613,
      "step": 6200
    },
    {
      "epoch": 1.0522799398697178,
      "grad_norm": 8.414213180541992,
      "learning_rate": 7.895440120260566e-06,
      "loss": 0.9034,
      "step": 6300
    },
    {
      "epoch": 1.068982796058126,
      "grad_norm": 8.255402565002441,
      "learning_rate": 7.862034407883749e-06,
      "loss": 0.8408,
      "step": 6400
    },
    {
      "epoch": 1.0856856522465341,
      "grad_norm": 13.3497896194458,
      "learning_rate": 7.828628695506932e-06,
      "loss": 0.8084,
      "step": 6500
    },
    {
      "epoch": 1.1023885084349423,
      "grad_norm": 11.321955680847168,
      "learning_rate": 7.795222983130117e-06,
      "loss": 0.8204,
      "step": 6600
    },
    {
      "epoch": 1.1190913646233507,
      "grad_norm": 7.878087043762207,
      "learning_rate": 7.7618172707533e-06,
      "loss": 0.806,
      "step": 6700
    },
    {
      "epoch": 1.1357942208117588,
      "grad_norm": 8.206093788146973,
      "learning_rate": 7.728411558376483e-06,
      "loss": 0.7671,
      "step": 6800
    },
    {
      "epoch": 1.152497077000167,
      "grad_norm": 4.466897487640381,
      "learning_rate": 7.695005845999667e-06,
      "loss": 0.8098,
      "step": 6900
    },
    {
      "epoch": 1.1691999331885752,
      "grad_norm": 9.136777877807617,
      "learning_rate": 7.66160013362285e-06,
      "loss": 0.7614,
      "step": 7000
    },
    {
      "epoch": 1.1859027893769833,
      "grad_norm": 10.458943367004395,
      "learning_rate": 7.6281944212460335e-06,
      "loss": 0.789,
      "step": 7100
    },
    {
      "epoch": 1.2026056455653917,
      "grad_norm": 8.920487403869629,
      "learning_rate": 7.594788708869217e-06,
      "loss": 0.8163,
      "step": 7200
    },
    {
      "epoch": 1.2193085017538,
      "grad_norm": 11.907374382019043,
      "learning_rate": 7.561382996492401e-06,
      "loss": 0.8456,
      "step": 7300
    },
    {
      "epoch": 1.236011357942208,
      "grad_norm": 11.242413520812988,
      "learning_rate": 7.527977284115584e-06,
      "loss": 0.8351,
      "step": 7400
    },
    {
      "epoch": 1.2527142141306165,
      "grad_norm": 7.634298801422119,
      "learning_rate": 7.494571571738768e-06,
      "loss": 0.8226,
      "step": 7500
    },
    {
      "epoch": 1.2694170703190246,
      "grad_norm": 6.187839031219482,
      "learning_rate": 7.461165859361952e-06,
      "loss": 0.6745,
      "step": 7600
    },
    {
      "epoch": 1.2861199265074328,
      "grad_norm": 10.539850234985352,
      "learning_rate": 7.427760146985134e-06,
      "loss": 0.7874,
      "step": 7700
    },
    {
      "epoch": 1.302822782695841,
      "grad_norm": 9.321468353271484,
      "learning_rate": 7.394354434608318e-06,
      "loss": 0.798,
      "step": 7800
    },
    {
      "epoch": 1.3195256388842491,
      "grad_norm": 9.315834999084473,
      "learning_rate": 7.360948722231502e-06,
      "loss": 0.8128,
      "step": 7900
    },
    {
      "epoch": 1.3362284950726575,
      "grad_norm": 10.940750122070312,
      "learning_rate": 7.327543009854686e-06,
      "loss": 0.8507,
      "step": 8000
    },
    {
      "epoch": 1.3529313512610657,
      "grad_norm": 9.26766586303711,
      "learning_rate": 7.294137297477869e-06,
      "loss": 0.8092,
      "step": 8100
    },
    {
      "epoch": 1.3696342074494738,
      "grad_norm": 8.949978828430176,
      "learning_rate": 7.260731585101053e-06,
      "loss": 0.8615,
      "step": 8200
    },
    {
      "epoch": 1.386337063637882,
      "grad_norm": 12.97923469543457,
      "learning_rate": 7.227325872724237e-06,
      "loss": 0.8706,
      "step": 8300
    },
    {
      "epoch": 1.4030399198262904,
      "grad_norm": 14.301050186157227,
      "learning_rate": 7.193920160347419e-06,
      "loss": 0.7851,
      "step": 8400
    },
    {
      "epoch": 1.4197427760146986,
      "grad_norm": 8.119084358215332,
      "learning_rate": 7.160514447970603e-06,
      "loss": 0.7693,
      "step": 8500
    },
    {
      "epoch": 1.4364456322031067,
      "grad_norm": 8.7316312789917,
      "learning_rate": 7.127108735593787e-06,
      "loss": 0.7526,
      "step": 8600
    },
    {
      "epoch": 1.453148488391515,
      "grad_norm": 9.916796684265137,
      "learning_rate": 7.09370302321697e-06,
      "loss": 0.7497,
      "step": 8700
    },
    {
      "epoch": 1.469851344579923,
      "grad_norm": 10.502571105957031,
      "learning_rate": 7.060297310840154e-06,
      "loss": 0.8774,
      "step": 8800
    },
    {
      "epoch": 1.4865542007683314,
      "grad_norm": 12.595232963562012,
      "learning_rate": 7.026891598463338e-06,
      "loss": 0.7831,
      "step": 8900
    },
    {
      "epoch": 1.5032570569567396,
      "grad_norm": 7.125169277191162,
      "learning_rate": 6.993485886086522e-06,
      "loss": 0.7788,
      "step": 9000
    },
    {
      "epoch": 1.5199599131451478,
      "grad_norm": 7.165116786956787,
      "learning_rate": 6.960080173709705e-06,
      "loss": 0.8135,
      "step": 9100
    },
    {
      "epoch": 1.5366627693335562,
      "grad_norm": 9.842970848083496,
      "learning_rate": 6.926674461332889e-06,
      "loss": 0.7684,
      "step": 9200
    },
    {
      "epoch": 1.5533656255219643,
      "grad_norm": 10.491227149963379,
      "learning_rate": 6.893268748956073e-06,
      "loss": 0.8123,
      "step": 9300
    },
    {
      "epoch": 1.5700684817103725,
      "grad_norm": 11.020601272583008,
      "learning_rate": 6.859863036579255e-06,
      "loss": 0.789,
      "step": 9400
    },
    {
      "epoch": 1.5867713378987807,
      "grad_norm": 11.962905883789062,
      "learning_rate": 6.826457324202439e-06,
      "loss": 0.8665,
      "step": 9500
    },
    {
      "epoch": 1.6034741940871888,
      "grad_norm": 12.055328369140625,
      "learning_rate": 6.793051611825623e-06,
      "loss": 0.7867,
      "step": 9600
    },
    {
      "epoch": 1.620177050275597,
      "grad_norm": 17.300813674926758,
      "learning_rate": 6.7596458994488065e-06,
      "loss": 0.7945,
      "step": 9700
    },
    {
      "epoch": 1.6368799064640054,
      "grad_norm": 10.618378639221191,
      "learning_rate": 6.72624018707199e-06,
      "loss": 0.7277,
      "step": 9800
    },
    {
      "epoch": 1.6535827626524136,
      "grad_norm": 12.515414237976074,
      "learning_rate": 6.6928344746951735e-06,
      "loss": 0.8195,
      "step": 9900
    },
    {
      "epoch": 1.670285618840822,
      "grad_norm": 9.346664428710938,
      "learning_rate": 6.659428762318357e-06,
      "loss": 0.84,
      "step": 10000
    },
    {
      "epoch": 1.68698847502923,
      "grad_norm": 10.371697425842285,
      "learning_rate": 6.6260230499415405e-06,
      "loss": 0.7846,
      "step": 10100
    },
    {
      "epoch": 1.7036913312176383,
      "grad_norm": 7.426969528198242,
      "learning_rate": 6.592617337564724e-06,
      "loss": 0.744,
      "step": 10200
    },
    {
      "epoch": 1.7203941874060464,
      "grad_norm": 11.01919937133789,
      "learning_rate": 6.559211625187908e-06,
      "loss": 0.769,
      "step": 10300
    },
    {
      "epoch": 1.7370970435944546,
      "grad_norm": 5.4092817306518555,
      "learning_rate": 6.525805912811092e-06,
      "loss": 0.8086,
      "step": 10400
    },
    {
      "epoch": 1.7537998997828628,
      "grad_norm": 21.1321964263916,
      "learning_rate": 6.492400200434274e-06,
      "loss": 0.8222,
      "step": 10500
    },
    {
      "epoch": 1.770502755971271,
      "grad_norm": 6.995510101318359,
      "learning_rate": 6.458994488057458e-06,
      "loss": 0.7909,
      "step": 10600
    },
    {
      "epoch": 1.7872056121596793,
      "grad_norm": 5.199754238128662,
      "learning_rate": 6.425588775680642e-06,
      "loss": 0.8347,
      "step": 10700
    },
    {
      "epoch": 1.8039084683480875,
      "grad_norm": 5.240053653717041,
      "learning_rate": 6.392183063303825e-06,
      "loss": 0.82,
      "step": 10800
    },
    {
      "epoch": 1.8206113245364959,
      "grad_norm": 13.91179370880127,
      "learning_rate": 6.358777350927009e-06,
      "loss": 0.7755,
      "step": 10900
    },
    {
      "epoch": 1.837314180724904,
      "grad_norm": 6.495522499084473,
      "learning_rate": 6.325371638550193e-06,
      "loss": 0.7649,
      "step": 11000
    },
    {
      "epoch": 1.8540170369133122,
      "grad_norm": 7.36610746383667,
      "learning_rate": 6.291965926173375e-06,
      "loss": 0.7965,
      "step": 11100
    },
    {
      "epoch": 1.8707198931017204,
      "grad_norm": 3.399116039276123,
      "learning_rate": 6.258560213796559e-06,
      "loss": 0.7743,
      "step": 11200
    },
    {
      "epoch": 1.8874227492901285,
      "grad_norm": 11.301819801330566,
      "learning_rate": 6.225154501419743e-06,
      "loss": 0.8441,
      "step": 11300
    },
    {
      "epoch": 1.9041256054785367,
      "grad_norm": 7.75764799118042,
      "learning_rate": 6.191748789042927e-06,
      "loss": 0.7967,
      "step": 11400
    },
    {
      "epoch": 1.920828461666945,
      "grad_norm": 7.790670394897461,
      "learning_rate": 6.15834307666611e-06,
      "loss": 0.7428,
      "step": 11500
    },
    {
      "epoch": 1.9375313178553533,
      "grad_norm": 8.988899230957031,
      "learning_rate": 6.124937364289294e-06,
      "loss": 0.8719,
      "step": 11600
    },
    {
      "epoch": 1.9542341740437614,
      "grad_norm": 7.482259273529053,
      "learning_rate": 6.091531651912478e-06,
      "loss": 0.8764,
      "step": 11700
    },
    {
      "epoch": 1.9709370302321698,
      "grad_norm": 6.615495681762695,
      "learning_rate": 6.058125939535661e-06,
      "loss": 0.7848,
      "step": 11800
    },
    {
      "epoch": 1.987639886420578,
      "grad_norm": 7.869071006774902,
      "learning_rate": 6.024720227158845e-06,
      "loss": 0.7872,
      "step": 11900
    },
    {
      "epoch": 2.004342742608986,
      "grad_norm": 3.4792392253875732,
      "learning_rate": 5.991314514782029e-06,
      "loss": 0.8061,
      "step": 12000
    },
    {
      "epoch": 2.0210455987973943,
      "grad_norm": 7.619948863983154,
      "learning_rate": 5.957908802405213e-06,
      "loss": 0.6898,
      "step": 12100
    },
    {
      "epoch": 2.0377484549858025,
      "grad_norm": 13.747328758239746,
      "learning_rate": 5.924503090028395e-06,
      "loss": 0.7086,
      "step": 12200
    },
    {
      "epoch": 2.0544513111742106,
      "grad_norm": 6.853213787078857,
      "learning_rate": 5.891097377651579e-06,
      "loss": 0.7025,
      "step": 12300
    },
    {
      "epoch": 2.071154167362619,
      "grad_norm": 10.329242706298828,
      "learning_rate": 5.857691665274763e-06,
      "loss": 0.6844,
      "step": 12400
    },
    {
      "epoch": 2.0878570235510274,
      "grad_norm": 10.690278053283691,
      "learning_rate": 5.824285952897946e-06,
      "loss": 0.7509,
      "step": 12500
    },
    {
      "epoch": 2.1045598797394356,
      "grad_norm": 11.551709175109863,
      "learning_rate": 5.79088024052113e-06,
      "loss": 0.8,
      "step": 12600
    },
    {
      "epoch": 2.1212627359278438,
      "grad_norm": 5.614315032958984,
      "learning_rate": 5.7574745281443135e-06,
      "loss": 0.6658,
      "step": 12700
    },
    {
      "epoch": 2.137965592116252,
      "grad_norm": 2.534313917160034,
      "learning_rate": 5.724068815767497e-06,
      "loss": 0.7283,
      "step": 12800
    },
    {
      "epoch": 2.15466844830466,
      "grad_norm": 11.718989372253418,
      "learning_rate": 5.6906631033906805e-06,
      "loss": 0.6664,
      "step": 12900
    },
    {
      "epoch": 2.1713713044930683,
      "grad_norm": 15.75721549987793,
      "learning_rate": 5.6572573910138635e-06,
      "loss": 0.7365,
      "step": 13000
    },
    {
      "epoch": 2.1880741606814764,
      "grad_norm": 5.660747051239014,
      "learning_rate": 5.6238516786370474e-06,
      "loss": 0.6777,
      "step": 13100
    },
    {
      "epoch": 2.2047770168698846,
      "grad_norm": 14.835000038146973,
      "learning_rate": 5.5904459662602305e-06,
      "loss": 0.7124,
      "step": 13200
    },
    {
      "epoch": 2.2214798730582928,
      "grad_norm": 6.574411869049072,
      "learning_rate": 5.557040253883414e-06,
      "loss": 0.7621,
      "step": 13300
    },
    {
      "epoch": 2.2381827292467014,
      "grad_norm": 7.124465465545654,
      "learning_rate": 5.523634541506598e-06,
      "loss": 0.7344,
      "step": 13400
    },
    {
      "epoch": 2.2548855854351095,
      "grad_norm": 8.806241989135742,
      "learning_rate": 5.490228829129781e-06,
      "loss": 0.6558,
      "step": 13500
    },
    {
      "epoch": 2.2715884416235177,
      "grad_norm": 17.120420455932617,
      "learning_rate": 5.456823116752965e-06,
      "loss": 0.6775,
      "step": 13600
    },
    {
      "epoch": 2.288291297811926,
      "grad_norm": 13.95682430267334,
      "learning_rate": 5.423417404376149e-06,
      "loss": 0.7203,
      "step": 13700
    },
    {
      "epoch": 2.304994154000334,
      "grad_norm": 5.652808666229248,
      "learning_rate": 5.390011691999333e-06,
      "loss": 0.7783,
      "step": 13800
    },
    {
      "epoch": 2.321697010188742,
      "grad_norm": 3.4253854751586914,
      "learning_rate": 5.356605979622515e-06,
      "loss": 0.6649,
      "step": 13900
    },
    {
      "epoch": 2.3383998663771504,
      "grad_norm": 7.867863655090332,
      "learning_rate": 5.323200267245699e-06,
      "loss": 0.7745,
      "step": 14000
    },
    {
      "epoch": 2.3551027225655585,
      "grad_norm": 6.578271865844727,
      "learning_rate": 5.289794554868883e-06,
      "loss": 0.7266,
      "step": 14100
    },
    {
      "epoch": 2.3718055787539667,
      "grad_norm": 7.820966720581055,
      "learning_rate": 5.256388842492066e-06,
      "loss": 0.7046,
      "step": 14200
    },
    {
      "epoch": 2.3885084349423753,
      "grad_norm": 12.092063903808594,
      "learning_rate": 5.22298313011525e-06,
      "loss": 0.6978,
      "step": 14300
    },
    {
      "epoch": 2.4052112911307835,
      "grad_norm": 8.61013412475586,
      "learning_rate": 5.189577417738434e-06,
      "loss": 0.7592,
      "step": 14400
    },
    {
      "epoch": 2.4219141473191916,
      "grad_norm": 10.68017578125,
      "learning_rate": 5.156171705361617e-06,
      "loss": 0.7161,
      "step": 14500
    },
    {
      "epoch": 2.4386170035076,
      "grad_norm": 11.306500434875488,
      "learning_rate": 5.122765992984801e-06,
      "loss": 0.7281,
      "step": 14600
    },
    {
      "epoch": 2.455319859696008,
      "grad_norm": 10.800307273864746,
      "learning_rate": 5.089360280607985e-06,
      "loss": 0.7627,
      "step": 14700
    },
    {
      "epoch": 2.472022715884416,
      "grad_norm": 12.061569213867188,
      "learning_rate": 5.055954568231169e-06,
      "loss": 0.6973,
      "step": 14800
    },
    {
      "epoch": 2.4887255720728243,
      "grad_norm": 8.457511901855469,
      "learning_rate": 5.022548855854351e-06,
      "loss": 0.7145,
      "step": 14900
    },
    {
      "epoch": 2.505428428261233,
      "grad_norm": 12.950366020202637,
      "learning_rate": 4.989143143477535e-06,
      "loss": 0.666,
      "step": 15000
    },
    {
      "epoch": 2.5221312844496406,
      "grad_norm": 8.498080253601074,
      "learning_rate": 4.955737431100719e-06,
      "loss": 0.6671,
      "step": 15100
    },
    {
      "epoch": 2.5388341406380492,
      "grad_norm": 9.99802303314209,
      "learning_rate": 4.922331718723903e-06,
      "loss": 0.7081,
      "step": 15200
    },
    {
      "epoch": 2.5555369968264574,
      "grad_norm": 15.173620223999023,
      "learning_rate": 4.888926006347086e-06,
      "loss": 0.6689,
      "step": 15300
    },
    {
      "epoch": 2.5722398530148656,
      "grad_norm": 10.21045207977295,
      "learning_rate": 4.85552029397027e-06,
      "loss": 0.7134,
      "step": 15400
    },
    {
      "epoch": 2.5889427092032737,
      "grad_norm": 15.126458168029785,
      "learning_rate": 4.822114581593453e-06,
      "loss": 0.7463,
      "step": 15500
    },
    {
      "epoch": 2.605645565391682,
      "grad_norm": 10.924276351928711,
      "learning_rate": 4.788708869216637e-06,
      "loss": 0.659,
      "step": 15600
    },
    {
      "epoch": 2.62234842158009,
      "grad_norm": 11.670296669006348,
      "learning_rate": 4.75530315683982e-06,
      "loss": 0.6682,
      "step": 15700
    },
    {
      "epoch": 2.6390512777684982,
      "grad_norm": 12.565372467041016,
      "learning_rate": 4.7218974444630036e-06,
      "loss": 0.6476,
      "step": 15800
    },
    {
      "epoch": 2.655754133956907,
      "grad_norm": 17.75897216796875,
      "learning_rate": 4.6884917320861875e-06,
      "loss": 0.7611,
      "step": 15900
    },
    {
      "epoch": 2.672456990145315,
      "grad_norm": 9.812529563903809,
      "learning_rate": 4.6550860197093705e-06,
      "loss": 0.7,
      "step": 16000
    },
    {
      "epoch": 2.689159846333723,
      "grad_norm": 12.08994197845459,
      "learning_rate": 4.6216803073325544e-06,
      "loss": 0.7346,
      "step": 16100
    },
    {
      "epoch": 2.7058627025221313,
      "grad_norm": 6.519437789916992,
      "learning_rate": 4.5882745949557375e-06,
      "loss": 0.6714,
      "step": 16200
    },
    {
      "epoch": 2.7225655587105395,
      "grad_norm": 13.141058921813965,
      "learning_rate": 4.554868882578921e-06,
      "loss": 0.701,
      "step": 16300
    },
    {
      "epoch": 2.7392684148989477,
      "grad_norm": 11.233685493469238,
      "learning_rate": 4.521463170202105e-06,
      "loss": 0.6808,
      "step": 16400
    },
    {
      "epoch": 2.755971271087356,
      "grad_norm": 10.984013557434082,
      "learning_rate": 4.488057457825288e-06,
      "loss": 0.7174,
      "step": 16500
    },
    {
      "epoch": 2.772674127275764,
      "grad_norm": 11.811448097229004,
      "learning_rate": 4.454651745448472e-06,
      "loss": 0.6785,
      "step": 16600
    },
    {
      "epoch": 2.789376983464172,
      "grad_norm": 11.604875564575195,
      "learning_rate": 4.421246033071655e-06,
      "loss": 0.6647,
      "step": 16700
    },
    {
      "epoch": 2.806079839652581,
      "grad_norm": 11.272716522216797,
      "learning_rate": 4.387840320694839e-06,
      "loss": 0.7221,
      "step": 16800
    },
    {
      "epoch": 2.822782695840989,
      "grad_norm": 9.377397537231445,
      "learning_rate": 4.354434608318023e-06,
      "loss": 0.7225,
      "step": 16900
    },
    {
      "epoch": 2.839485552029397,
      "grad_norm": 4.839840888977051,
      "learning_rate": 4.321028895941206e-06,
      "loss": 0.7242,
      "step": 17000
    },
    {
      "epoch": 2.8561884082178053,
      "grad_norm": 10.537065505981445,
      "learning_rate": 4.28762318356439e-06,
      "loss": 0.7287,
      "step": 17100
    },
    {
      "epoch": 2.8728912644062135,
      "grad_norm": 10.46806526184082,
      "learning_rate": 4.254217471187573e-06,
      "loss": 0.7009,
      "step": 17200
    },
    {
      "epoch": 2.8895941205946216,
      "grad_norm": 11.026208877563477,
      "learning_rate": 4.220811758810757e-06,
      "loss": 0.724,
      "step": 17300
    },
    {
      "epoch": 2.90629697678303,
      "grad_norm": 6.356370449066162,
      "learning_rate": 4.187406046433941e-06,
      "loss": 0.6605,
      "step": 17400
    },
    {
      "epoch": 2.922999832971438,
      "grad_norm": 25.513717651367188,
      "learning_rate": 4.154000334057124e-06,
      "loss": 0.7189,
      "step": 17500
    },
    {
      "epoch": 2.939702689159846,
      "grad_norm": 10.040546417236328,
      "learning_rate": 4.120594621680308e-06,
      "loss": 0.6557,
      "step": 17600
    },
    {
      "epoch": 2.9564055453482547,
      "grad_norm": 8.02794361114502,
      "learning_rate": 4.087188909303491e-06,
      "loss": 0.7272,
      "step": 17700
    },
    {
      "epoch": 2.973108401536663,
      "grad_norm": 15.75390338897705,
      "learning_rate": 4.053783196926675e-06,
      "loss": 0.7338,
      "step": 17800
    },
    {
      "epoch": 2.989811257725071,
      "grad_norm": 7.299880504608154,
      "learning_rate": 4.020377484549858e-06,
      "loss": 0.6391,
      "step": 17900
    },
    {
      "epoch": 3.0065141139134792,
      "grad_norm": 10.362414360046387,
      "learning_rate": 3.986971772173042e-06,
      "loss": 0.6555,
      "step": 18000
    },
    {
      "epoch": 3.0232169701018874,
      "grad_norm": 15.8690824508667,
      "learning_rate": 3.953566059796226e-06,
      "loss": 0.594,
      "step": 18100
    },
    {
      "epoch": 3.0399198262902956,
      "grad_norm": 3.154592514038086,
      "learning_rate": 3.920160347419409e-06,
      "loss": 0.6526,
      "step": 18200
    },
    {
      "epoch": 3.0566226824787037,
      "grad_norm": 11.878024101257324,
      "learning_rate": 3.886754635042593e-06,
      "loss": 0.6557,
      "step": 18300
    },
    {
      "epoch": 3.073325538667112,
      "grad_norm": 7.638818740844727,
      "learning_rate": 3.853348922665776e-06,
      "loss": 0.6228,
      "step": 18400
    },
    {
      "epoch": 3.0900283948555205,
      "grad_norm": 6.099075794219971,
      "learning_rate": 3.81994321028896e-06,
      "loss": 0.5189,
      "step": 18500
    },
    {
      "epoch": 3.1067312510439287,
      "grad_norm": 19.946672439575195,
      "learning_rate": 3.786537497912143e-06,
      "loss": 0.5896,
      "step": 18600
    },
    {
      "epoch": 3.123434107232337,
      "grad_norm": 12.871219635009766,
      "learning_rate": 3.7531317855353266e-06,
      "loss": 0.6565,
      "step": 18700
    },
    {
      "epoch": 3.140136963420745,
      "grad_norm": 5.81707239151001,
      "learning_rate": 3.7197260731585105e-06,
      "loss": 0.6902,
      "step": 18800
    },
    {
      "epoch": 3.156839819609153,
      "grad_norm": 11.315629959106445,
      "learning_rate": 3.686320360781694e-06,
      "loss": 0.6575,
      "step": 18900
    },
    {
      "epoch": 3.1735426757975613,
      "grad_norm": 10.695049285888672,
      "learning_rate": 3.652914648404878e-06,
      "loss": 0.6143,
      "step": 19000
    },
    {
      "epoch": 3.1902455319859695,
      "grad_norm": 14.84745979309082,
      "learning_rate": 3.619508936028061e-06,
      "loss": 0.6391,
      "step": 19100
    },
    {
      "epoch": 3.2069483881743777,
      "grad_norm": 15.754920959472656,
      "learning_rate": 3.5861032236512445e-06,
      "loss": 0.6042,
      "step": 19200
    },
    {
      "epoch": 3.2236512443627863,
      "grad_norm": 17.652746200561523,
      "learning_rate": 3.5526975112744284e-06,
      "loss": 0.6022,
      "step": 19300
    },
    {
      "epoch": 3.2403541005511944,
      "grad_norm": 8.378828048706055,
      "learning_rate": 3.5192917988976114e-06,
      "loss": 0.577,
      "step": 19400
    },
    {
      "epoch": 3.2570569567396026,
      "grad_norm": 14.373273849487305,
      "learning_rate": 3.4858860865207953e-06,
      "loss": 0.6917,
      "step": 19500
    },
    {
      "epoch": 3.2737598129280108,
      "grad_norm": 4.668178558349609,
      "learning_rate": 3.452480374143979e-06,
      "loss": 0.5864,
      "step": 19600
    },
    {
      "epoch": 3.290462669116419,
      "grad_norm": 13.615735054016113,
      "learning_rate": 3.4190746617671627e-06,
      "loss": 0.6127,
      "step": 19700
    },
    {
      "epoch": 3.307165525304827,
      "grad_norm": 13.62197208404541,
      "learning_rate": 3.385668949390346e-06,
      "loss": 0.6235,
      "step": 19800
    },
    {
      "epoch": 3.3238683814932353,
      "grad_norm": 11.980979919433594,
      "learning_rate": 3.3522632370135293e-06,
      "loss": 0.6103,
      "step": 19900
    },
    {
      "epoch": 3.3405712376816434,
      "grad_norm": 14.22753620147705,
      "learning_rate": 3.318857524636713e-06,
      "loss": 0.6221,
      "step": 20000
    },
    {
      "epoch": 3.3572740938700516,
      "grad_norm": 8.070207595825195,
      "learning_rate": 3.2854518122598966e-06,
      "loss": 0.6523,
      "step": 20100
    },
    {
      "epoch": 3.37397695005846,
      "grad_norm": 24.9392147064209,
      "learning_rate": 3.2520460998830805e-06,
      "loss": 0.6668,
      "step": 20200
    },
    {
      "epoch": 3.3906798062468684,
      "grad_norm": 4.186945915222168,
      "learning_rate": 3.218640387506264e-06,
      "loss": 0.6493,
      "step": 20300
    },
    {
      "epoch": 3.4073826624352765,
      "grad_norm": 15.710217475891113,
      "learning_rate": 3.185234675129447e-06,
      "loss": 0.5914,
      "step": 20400
    },
    {
      "epoch": 3.4240855186236847,
      "grad_norm": 8.981027603149414,
      "learning_rate": 3.151828962752631e-06,
      "loss": 0.576,
      "step": 20500
    },
    {
      "epoch": 3.440788374812093,
      "grad_norm": 14.60678482055664,
      "learning_rate": 3.1184232503758145e-06,
      "loss": 0.5947,
      "step": 20600
    },
    {
      "epoch": 3.457491231000501,
      "grad_norm": 11.113763809204102,
      "learning_rate": 3.0850175379989984e-06,
      "loss": 0.6722,
      "step": 20700
    },
    {
      "epoch": 3.474194087188909,
      "grad_norm": 5.631390571594238,
      "learning_rate": 3.0516118256221814e-06,
      "loss": 0.6187,
      "step": 20800
    },
    {
      "epoch": 3.4908969433773174,
      "grad_norm": 13.845147132873535,
      "learning_rate": 3.018206113245365e-06,
      "loss": 0.5532,
      "step": 20900
    },
    {
      "epoch": 3.5075997995657255,
      "grad_norm": 26.966217041015625,
      "learning_rate": 2.984800400868549e-06,
      "loss": 0.6752,
      "step": 21000
    },
    {
      "epoch": 3.524302655754134,
      "grad_norm": 9.143012046813965,
      "learning_rate": 2.9513946884917323e-06,
      "loss": 0.6041,
      "step": 21100
    },
    {
      "epoch": 3.5410055119425423,
      "grad_norm": 17.562877655029297,
      "learning_rate": 2.917988976114916e-06,
      "loss": 0.6283,
      "step": 21200
    },
    {
      "epoch": 3.5577083681309505,
      "grad_norm": 14.615344047546387,
      "learning_rate": 2.8845832637380993e-06,
      "loss": 0.5547,
      "step": 21300
    },
    {
      "epoch": 3.5744112243193586,
      "grad_norm": 16.755765914916992,
      "learning_rate": 2.851177551361283e-06,
      "loss": 0.6214,
      "step": 21400
    },
    {
      "epoch": 3.591114080507767,
      "grad_norm": 20.99614143371582,
      "learning_rate": 2.8177718389844666e-06,
      "loss": 0.6062,
      "step": 21500
    },
    {
      "epoch": 3.607816936696175,
      "grad_norm": 10.594215393066406,
      "learning_rate": 2.78436612660765e-06,
      "loss": 0.5665,
      "step": 21600
    },
    {
      "epoch": 3.624519792884583,
      "grad_norm": 5.716753005981445,
      "learning_rate": 2.7509604142308336e-06,
      "loss": 0.5985,
      "step": 21700
    },
    {
      "epoch": 3.6412226490729918,
      "grad_norm": 15.087369918823242,
      "learning_rate": 2.717554701854017e-06,
      "loss": 0.6091,
      "step": 21800
    },
    {
      "epoch": 3.6579255052613995,
      "grad_norm": 17.249170303344727,
      "learning_rate": 2.684148989477201e-06,
      "loss": 0.6481,
      "step": 21900
    },
    {
      "epoch": 3.674628361449808,
      "grad_norm": 15.252999305725098,
      "learning_rate": 2.6507432771003845e-06,
      "loss": 0.6507,
      "step": 22000
    },
    {
      "epoch": 3.6913312176382163,
      "grad_norm": 6.677545547485352,
      "learning_rate": 2.6173375647235675e-06,
      "loss": 0.6411,
      "step": 22100
    },
    {
      "epoch": 3.7080340738266244,
      "grad_norm": 13.379900932312012,
      "learning_rate": 2.5839318523467514e-06,
      "loss": 0.6122,
      "step": 22200
    },
    {
      "epoch": 3.7247369300150326,
      "grad_norm": 29.009002685546875,
      "learning_rate": 2.550526139969935e-06,
      "loss": 0.6436,
      "step": 22300
    },
    {
      "epoch": 3.7414397862034408,
      "grad_norm": 17.63412094116211,
      "learning_rate": 2.517120427593119e-06,
      "loss": 0.6672,
      "step": 22400
    },
    {
      "epoch": 3.758142642391849,
      "grad_norm": 15.461082458496094,
      "learning_rate": 2.4837147152163023e-06,
      "loss": 0.607,
      "step": 22500
    },
    {
      "epoch": 3.774845498580257,
      "grad_norm": 15.593780517578125,
      "learning_rate": 2.4503090028394858e-06,
      "loss": 0.5751,
      "step": 22600
    },
    {
      "epoch": 3.7915483547686657,
      "grad_norm": 22.74703025817871,
      "learning_rate": 2.4169032904626693e-06,
      "loss": 0.6201,
      "step": 22700
    },
    {
      "epoch": 3.8082512109570734,
      "grad_norm": 15.841890335083008,
      "learning_rate": 2.383497578085853e-06,
      "loss": 0.6391,
      "step": 22800
    },
    {
      "epoch": 3.824954067145482,
      "grad_norm": 14.29261302947998,
      "learning_rate": 2.3500918657090362e-06,
      "loss": 0.6596,
      "step": 22900
    },
    {
      "epoch": 3.84165692333389,
      "grad_norm": 15.084193229675293,
      "learning_rate": 2.3166861533322197e-06,
      "loss": 0.6136,
      "step": 23000
    },
    {
      "epoch": 3.8583597795222984,
      "grad_norm": 13.914113998413086,
      "learning_rate": 2.2832804409554036e-06,
      "loss": 0.6459,
      "step": 23100
    },
    {
      "epoch": 3.8750626357107065,
      "grad_norm": 14.336692810058594,
      "learning_rate": 2.249874728578587e-06,
      "loss": 0.6496,
      "step": 23200
    },
    {
      "epoch": 3.8917654918991147,
      "grad_norm": 14.537676811218262,
      "learning_rate": 2.2164690162017706e-06,
      "loss": 0.6134,
      "step": 23300
    },
    {
      "epoch": 3.908468348087523,
      "grad_norm": 18.918546676635742,
      "learning_rate": 2.1830633038249545e-06,
      "loss": 0.6388,
      "step": 23400
    },
    {
      "epoch": 3.925171204275931,
      "grad_norm": 11.998445510864258,
      "learning_rate": 2.1496575914481375e-06,
      "loss": 0.612,
      "step": 23500
    },
    {
      "epoch": 3.9418740604643396,
      "grad_norm": 8.759129524230957,
      "learning_rate": 2.1162518790713214e-06,
      "loss": 0.5926,
      "step": 23600
    },
    {
      "epoch": 3.9585769166527474,
      "grad_norm": 9.172672271728516,
      "learning_rate": 2.082846166694505e-06,
      "loss": 0.6148,
      "step": 23700
    },
    {
      "epoch": 3.975279772841156,
      "grad_norm": 12.303715705871582,
      "learning_rate": 2.0494404543176884e-06,
      "loss": 0.6137,
      "step": 23800
    },
    {
      "epoch": 3.991982629029564,
      "grad_norm": 20.556100845336914,
      "learning_rate": 2.0160347419408723e-06,
      "loss": 0.5487,
      "step": 23900
    },
    {
      "epoch": 4.008685485217972,
      "grad_norm": 13.481053352355957,
      "learning_rate": 1.982629029564056e-06,
      "loss": 0.5933,
      "step": 24000
    },
    {
      "epoch": 4.025388341406381,
      "grad_norm": 3.0865275859832764,
      "learning_rate": 1.949223317187239e-06,
      "loss": 0.4827,
      "step": 24100
    },
    {
      "epoch": 4.042091197594789,
      "grad_norm": 13.469022750854492,
      "learning_rate": 1.9158176048104228e-06,
      "loss": 0.5134,
      "step": 24200
    },
    {
      "epoch": 4.058794053783197,
      "grad_norm": 9.112001419067383,
      "learning_rate": 1.8824118924336062e-06,
      "loss": 0.5326,
      "step": 24300
    },
    {
      "epoch": 4.075496909971605,
      "grad_norm": 17.8978214263916,
      "learning_rate": 1.84900618005679e-06,
      "loss": 0.5174,
      "step": 24400
    },
    {
      "epoch": 4.092199766160014,
      "grad_norm": 9.47776985168457,
      "learning_rate": 1.8156004676799734e-06,
      "loss": 0.562,
      "step": 24500
    },
    {
      "epoch": 4.108902622348421,
      "grad_norm": 12.863837242126465,
      "learning_rate": 1.782194755303157e-06,
      "loss": 0.5306,
      "step": 24600
    },
    {
      "epoch": 4.12560547853683,
      "grad_norm": 5.144862174987793,
      "learning_rate": 1.7487890429263404e-06,
      "loss": 0.5621,
      "step": 24700
    },
    {
      "epoch": 4.142308334725238,
      "grad_norm": 34.66820526123047,
      "learning_rate": 1.715383330549524e-06,
      "loss": 0.5172,
      "step": 24800
    },
    {
      "epoch": 4.159011190913646,
      "grad_norm": 18.21342658996582,
      "learning_rate": 1.6819776181727078e-06,
      "loss": 0.5429,
      "step": 24900
    },
    {
      "epoch": 4.175714047102055,
      "grad_norm": 10.91688060760498,
      "learning_rate": 1.6485719057958912e-06,
      "loss": 0.5978,
      "step": 25000
    },
    {
      "epoch": 4.192416903290463,
      "grad_norm": 2.886237859725952,
      "learning_rate": 1.615166193419075e-06,
      "loss": 0.5602,
      "step": 25100
    },
    {
      "epoch": 4.209119759478871,
      "grad_norm": 15.23075008392334,
      "learning_rate": 1.5817604810422584e-06,
      "loss": 0.5329,
      "step": 25200
    },
    {
      "epoch": 4.225822615667279,
      "grad_norm": 17.185768127441406,
      "learning_rate": 1.548354768665442e-06,
      "loss": 0.5776,
      "step": 25300
    },
    {
      "epoch": 4.2425254718556875,
      "grad_norm": 16.52889060974121,
      "learning_rate": 1.5149490562886254e-06,
      "loss": 0.5373,
      "step": 25400
    },
    {
      "epoch": 4.259228328044095,
      "grad_norm": 12.323935508728027,
      "learning_rate": 1.481543343911809e-06,
      "loss": 0.537,
      "step": 25500
    },
    {
      "epoch": 4.275931184232504,
      "grad_norm": 9.151744842529297,
      "learning_rate": 1.4481376315349926e-06,
      "loss": 0.5585,
      "step": 25600
    },
    {
      "epoch": 4.292634040420912,
      "grad_norm": 11.404494285583496,
      "learning_rate": 1.4147319191581762e-06,
      "loss": 0.5186,
      "step": 25700
    },
    {
      "epoch": 4.30933689660932,
      "grad_norm": 17.35771942138672,
      "learning_rate": 1.3813262067813595e-06,
      "loss": 0.5414,
      "step": 25800
    },
    {
      "epoch": 4.326039752797729,
      "grad_norm": 5.77121114730835,
      "learning_rate": 1.3479204944045432e-06,
      "loss": 0.522,
      "step": 25900
    },
    {
      "epoch": 4.3427426089861365,
      "grad_norm": 3.513676404953003,
      "learning_rate": 1.314514782027727e-06,
      "loss": 0.5878,
      "step": 26000
    },
    {
      "epoch": 4.359445465174545,
      "grad_norm": 16.364151000976562,
      "learning_rate": 1.2811090696509104e-06,
      "loss": 0.5199,
      "step": 26100
    },
    {
      "epoch": 4.376148321362953,
      "grad_norm": 8.332428932189941,
      "learning_rate": 1.247703357274094e-06,
      "loss": 0.536,
      "step": 26200
    },
    {
      "epoch": 4.3928511775513615,
      "grad_norm": 7.468430995941162,
      "learning_rate": 1.2142976448972776e-06,
      "loss": 0.5346,
      "step": 26300
    },
    {
      "epoch": 4.409554033739769,
      "grad_norm": 18.458467483520508,
      "learning_rate": 1.180891932520461e-06,
      "loss": 0.4985,
      "step": 26400
    },
    {
      "epoch": 4.426256889928178,
      "grad_norm": 12.845380783081055,
      "learning_rate": 1.1474862201436447e-06,
      "loss": 0.6187,
      "step": 26500
    },
    {
      "epoch": 4.4429597461165855,
      "grad_norm": 21.37894058227539,
      "learning_rate": 1.1140805077668282e-06,
      "loss": 0.5565,
      "step": 26600
    },
    {
      "epoch": 4.459662602304994,
      "grad_norm": 17.18465232849121,
      "learning_rate": 1.080674795390012e-06,
      "loss": 0.5329,
      "step": 26700
    },
    {
      "epoch": 4.476365458493403,
      "grad_norm": 17.78074836730957,
      "learning_rate": 1.0472690830131954e-06,
      "loss": 0.5773,
      "step": 26800
    },
    {
      "epoch": 4.4930683146818104,
      "grad_norm": 20.825124740600586,
      "learning_rate": 1.0138633706363789e-06,
      "loss": 0.59,
      "step": 26900
    },
    {
      "epoch": 4.509771170870219,
      "grad_norm": 12.047731399536133,
      "learning_rate": 9.804576582595626e-07,
      "loss": 0.4441,
      "step": 27000
    },
    {
      "epoch": 4.526474027058627,
      "grad_norm": 12.655083656311035,
      "learning_rate": 9.470519458827459e-07,
      "loss": 0.5348,
      "step": 27100
    },
    {
      "epoch": 4.543176883247035,
      "grad_norm": 18.071889877319336,
      "learning_rate": 9.136462335059295e-07,
      "loss": 0.4681,
      "step": 27200
    },
    {
      "epoch": 4.559879739435443,
      "grad_norm": 18.536865234375,
      "learning_rate": 8.802405211291132e-07,
      "loss": 0.5289,
      "step": 27300
    },
    {
      "epoch": 4.576582595623852,
      "grad_norm": 11.414491653442383,
      "learning_rate": 8.468348087522967e-07,
      "loss": 0.482,
      "step": 27400
    },
    {
      "epoch": 4.59328545181226,
      "grad_norm": 8.468878746032715,
      "learning_rate": 8.134290963754803e-07,
      "loss": 0.5499,
      "step": 27500
    },
    {
      "epoch": 4.609988308000668,
      "grad_norm": 16.21770668029785,
      "learning_rate": 7.800233839986639e-07,
      "loss": 0.5036,
      "step": 27600
    },
    {
      "epoch": 4.626691164189077,
      "grad_norm": 17.804792404174805,
      "learning_rate": 7.466176716218474e-07,
      "loss": 0.5536,
      "step": 27700
    },
    {
      "epoch": 4.643394020377484,
      "grad_norm": 16.93807029724121,
      "learning_rate": 7.132119592450309e-07,
      "loss": 0.5556,
      "step": 27800
    },
    {
      "epoch": 4.660096876565893,
      "grad_norm": 22.484375,
      "learning_rate": 6.798062468682145e-07,
      "loss": 0.5334,
      "step": 27900
    },
    {
      "epoch": 4.676799732754301,
      "grad_norm": 8.833635330200195,
      "learning_rate": 6.46400534491398e-07,
      "loss": 0.5322,
      "step": 28000
    },
    {
      "epoch": 4.693502588942709,
      "grad_norm": 17.481998443603516,
      "learning_rate": 6.129948221145816e-07,
      "loss": 0.5376,
      "step": 28100
    },
    {
      "epoch": 4.710205445131117,
      "grad_norm": 12.138877868652344,
      "learning_rate": 5.795891097377652e-07,
      "loss": 0.4698,
      "step": 28200
    },
    {
      "epoch": 4.726908301319526,
      "grad_norm": 29.38081932067871,
      "learning_rate": 5.461833973609488e-07,
      "loss": 0.5479,
      "step": 28300
    },
    {
      "epoch": 4.743611157507933,
      "grad_norm": 9.614446640014648,
      "learning_rate": 5.127776849841324e-07,
      "loss": 0.5351,
      "step": 28400
    },
    {
      "epoch": 4.760314013696342,
      "grad_norm": 11.042581558227539,
      "learning_rate": 4.793719726073158e-07,
      "loss": 0.5135,
      "step": 28500
    },
    {
      "epoch": 4.777016869884751,
      "grad_norm": 23.132421493530273,
      "learning_rate": 4.459662602304995e-07,
      "loss": 0.5681,
      "step": 28600
    },
    {
      "epoch": 4.793719726073158,
      "grad_norm": 1.9319372177124023,
      "learning_rate": 4.12560547853683e-07,
      "loss": 0.6659,
      "step": 28700
    },
    {
      "epoch": 4.810422582261567,
      "grad_norm": 7.389389514923096,
      "learning_rate": 3.7915483547686655e-07,
      "loss": 0.6231,
      "step": 28800
    },
    {
      "epoch": 4.827125438449975,
      "grad_norm": 6.770929336547852,
      "learning_rate": 3.457491231000502e-07,
      "loss": 0.5027,
      "step": 28900
    },
    {
      "epoch": 4.843828294638383,
      "grad_norm": 15.059926986694336,
      "learning_rate": 3.123434107232337e-07,
      "loss": 0.6146,
      "step": 29000
    }
  ],
  "logging_steps": 100,
  "max_steps": 29935,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "total_flos": 7629842103625728.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
