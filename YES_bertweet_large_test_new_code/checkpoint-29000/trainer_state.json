{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.843828294638383,
  "eval_steps": 500,
  "global_step": 29000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.016702856188408218,
      "grad_norm": 33.46145248413086,
      "learning_rate": 9.966594287623184e-06,
      "loss": 1.4578,
      "step": 100
    },
    {
      "epoch": 0.033405712376816436,
      "grad_norm": 19.915555953979492,
      "learning_rate": 9.933188575246367e-06,
      "loss": 1.3298,
      "step": 200
    },
    {
      "epoch": 0.05010856856522465,
      "grad_norm": 13.812671661376953,
      "learning_rate": 9.899782862869552e-06,
      "loss": 1.1506,
      "step": 300
    },
    {
      "epoch": 0.06681142475363287,
      "grad_norm": 11.676016807556152,
      "learning_rate": 9.866377150492735e-06,
      "loss": 1.0759,
      "step": 400
    },
    {
      "epoch": 0.0835142809420411,
      "grad_norm": 38.547237396240234,
      "learning_rate": 9.83297143811592e-06,
      "loss": 1.017,
      "step": 500
    },
    {
      "epoch": 0.1002171371304493,
      "grad_norm": 22.802419662475586,
      "learning_rate": 9.799565725739103e-06,
      "loss": 1.0167,
      "step": 600
    },
    {
      "epoch": 0.11691999331885752,
      "grad_norm": 22.268299102783203,
      "learning_rate": 9.766160013362286e-06,
      "loss": 1.0161,
      "step": 700
    },
    {
      "epoch": 0.13362284950726575,
      "grad_norm": 15.123230934143066,
      "learning_rate": 9.73275430098547e-06,
      "loss": 1.0253,
      "step": 800
    },
    {
      "epoch": 0.15032570569567397,
      "grad_norm": 6.961587429046631,
      "learning_rate": 9.699348588608652e-06,
      "loss": 0.943,
      "step": 900
    },
    {
      "epoch": 0.1670285618840822,
      "grad_norm": 11.835333824157715,
      "learning_rate": 9.665942876231836e-06,
      "loss": 0.9251,
      "step": 1000
    },
    {
      "epoch": 0.18373141807249038,
      "grad_norm": 33.02470016479492,
      "learning_rate": 9.63253716385502e-06,
      "loss": 0.8824,
      "step": 1100
    },
    {
      "epoch": 0.2004342742608986,
      "grad_norm": 12.120888710021973,
      "learning_rate": 9.599131451478203e-06,
      "loss": 0.9479,
      "step": 1200
    },
    {
      "epoch": 0.21713713044930683,
      "grad_norm": 25.51107406616211,
      "learning_rate": 9.565725739101387e-06,
      "loss": 0.9853,
      "step": 1300
    },
    {
      "epoch": 0.23383998663771505,
      "grad_norm": 31.540300369262695,
      "learning_rate": 9.53232002672457e-06,
      "loss": 0.9906,
      "step": 1400
    },
    {
      "epoch": 0.25054284282612327,
      "grad_norm": 14.210817337036133,
      "learning_rate": 9.498914314347755e-06,
      "loss": 0.9485,
      "step": 1500
    },
    {
      "epoch": 0.2672456990145315,
      "grad_norm": 31.355567932128906,
      "learning_rate": 9.465508601970938e-06,
      "loss": 0.8902,
      "step": 1600
    },
    {
      "epoch": 0.2839485552029397,
      "grad_norm": 28.208282470703125,
      "learning_rate": 9.432102889594121e-06,
      "loss": 0.875,
      "step": 1700
    },
    {
      "epoch": 0.30065141139134793,
      "grad_norm": 20.28922462463379,
      "learning_rate": 9.398697177217306e-06,
      "loss": 0.878,
      "step": 1800
    },
    {
      "epoch": 0.31735426757975616,
      "grad_norm": 20.66668128967285,
      "learning_rate": 9.365291464840487e-06,
      "loss": 0.9374,
      "step": 1900
    },
    {
      "epoch": 0.3340571237681644,
      "grad_norm": 32.18619155883789,
      "learning_rate": 9.331885752463672e-06,
      "loss": 0.8502,
      "step": 2000
    },
    {
      "epoch": 0.3507599799565726,
      "grad_norm": 24.138931274414062,
      "learning_rate": 9.298480040086855e-06,
      "loss": 0.8874,
      "step": 2100
    },
    {
      "epoch": 0.36746283614498076,
      "grad_norm": 21.629117965698242,
      "learning_rate": 9.26507432771004e-06,
      "loss": 0.9298,
      "step": 2200
    },
    {
      "epoch": 0.384165692333389,
      "grad_norm": 16.20891761779785,
      "learning_rate": 9.231668615333223e-06,
      "loss": 0.9566,
      "step": 2300
    },
    {
      "epoch": 0.4008685485217972,
      "grad_norm": 11.819145202636719,
      "learning_rate": 9.198262902956406e-06,
      "loss": 0.9614,
      "step": 2400
    },
    {
      "epoch": 0.41757140471020543,
      "grad_norm": 19.119199752807617,
      "learning_rate": 9.16485719057959e-06,
      "loss": 0.9293,
      "step": 2500
    },
    {
      "epoch": 0.43427426089861365,
      "grad_norm": 8.24630069732666,
      "learning_rate": 9.131451478202772e-06,
      "loss": 0.8386,
      "step": 2600
    },
    {
      "epoch": 0.4509771170870219,
      "grad_norm": 38.158172607421875,
      "learning_rate": 9.098045765825957e-06,
      "loss": 0.8824,
      "step": 2700
    },
    {
      "epoch": 0.4676799732754301,
      "grad_norm": 18.827421188354492,
      "learning_rate": 9.06464005344914e-06,
      "loss": 0.9688,
      "step": 2800
    },
    {
      "epoch": 0.4843828294638383,
      "grad_norm": 15.196760177612305,
      "learning_rate": 9.031234341072323e-06,
      "loss": 0.9067,
      "step": 2900
    },
    {
      "epoch": 0.5010856856522465,
      "grad_norm": 19.26517677307129,
      "learning_rate": 8.997828628695508e-06,
      "loss": 0.9228,
      "step": 3000
    },
    {
      "epoch": 0.5177885418406547,
      "grad_norm": 7.235235691070557,
      "learning_rate": 8.964422916318691e-06,
      "loss": 0.8711,
      "step": 3100
    },
    {
      "epoch": 0.534491398029063,
      "grad_norm": 16.3454532623291,
      "learning_rate": 8.931017203941876e-06,
      "loss": 0.8631,
      "step": 3200
    },
    {
      "epoch": 0.5511942542174711,
      "grad_norm": 12.719253540039062,
      "learning_rate": 8.897611491565059e-06,
      "loss": 0.9171,
      "step": 3300
    },
    {
      "epoch": 0.5678971104058794,
      "grad_norm": 16.860212326049805,
      "learning_rate": 8.864205779188242e-06,
      "loss": 0.8952,
      "step": 3400
    },
    {
      "epoch": 0.5845999665942876,
      "grad_norm": 13.577434539794922,
      "learning_rate": 8.830800066811426e-06,
      "loss": 0.8853,
      "step": 3500
    },
    {
      "epoch": 0.6013028227826959,
      "grad_norm": 21.950923919677734,
      "learning_rate": 8.797394354434608e-06,
      "loss": 0.8765,
      "step": 3600
    },
    {
      "epoch": 0.618005678971104,
      "grad_norm": 15.983104705810547,
      "learning_rate": 8.763988642057793e-06,
      "loss": 0.8422,
      "step": 3700
    },
    {
      "epoch": 0.6347085351595123,
      "grad_norm": 7.790172100067139,
      "learning_rate": 8.730582929680976e-06,
      "loss": 0.8822,
      "step": 3800
    },
    {
      "epoch": 0.6514113913479205,
      "grad_norm": 14.528986930847168,
      "learning_rate": 8.69717721730416e-06,
      "loss": 0.9515,
      "step": 3900
    },
    {
      "epoch": 0.6681142475363288,
      "grad_norm": 18.229372024536133,
      "learning_rate": 8.663771504927343e-06,
      "loss": 0.8228,
      "step": 4000
    },
    {
      "epoch": 0.6848171037247369,
      "grad_norm": 18.610633850097656,
      "learning_rate": 8.630365792550527e-06,
      "loss": 0.9432,
      "step": 4100
    },
    {
      "epoch": 0.7015199599131452,
      "grad_norm": 7.047270774841309,
      "learning_rate": 8.596960080173711e-06,
      "loss": 0.9125,
      "step": 4200
    },
    {
      "epoch": 0.7182228161015534,
      "grad_norm": 10.99247932434082,
      "learning_rate": 8.563554367796894e-06,
      "loss": 0.8481,
      "step": 4300
    },
    {
      "epoch": 0.7349256722899615,
      "grad_norm": 34.76561737060547,
      "learning_rate": 8.530148655420077e-06,
      "loss": 0.8615,
      "step": 4400
    },
    {
      "epoch": 0.7516285284783698,
      "grad_norm": 22.934904098510742,
      "learning_rate": 8.496742943043262e-06,
      "loss": 0.9152,
      "step": 4500
    },
    {
      "epoch": 0.768331384666778,
      "grad_norm": 12.95914363861084,
      "learning_rate": 8.463337230666445e-06,
      "loss": 0.8928,
      "step": 4600
    },
    {
      "epoch": 0.7850342408551862,
      "grad_norm": 13.652582168579102,
      "learning_rate": 8.429931518289628e-06,
      "loss": 0.9106,
      "step": 4700
    },
    {
      "epoch": 0.8017370970435944,
      "grad_norm": 13.05276107788086,
      "learning_rate": 8.396525805912811e-06,
      "loss": 0.7798,
      "step": 4800
    },
    {
      "epoch": 0.8184399532320027,
      "grad_norm": 13.09522533416748,
      "learning_rate": 8.363120093535996e-06,
      "loss": 0.9355,
      "step": 4900
    },
    {
      "epoch": 0.8351428094204109,
      "grad_norm": 17.71552276611328,
      "learning_rate": 8.329714381159179e-06,
      "loss": 0.8411,
      "step": 5000
    },
    {
      "epoch": 0.8518456656088191,
      "grad_norm": 12.16385555267334,
      "learning_rate": 8.296308668782362e-06,
      "loss": 0.8949,
      "step": 5100
    },
    {
      "epoch": 0.8685485217972273,
      "grad_norm": 8.082709312438965,
      "learning_rate": 8.262902956405547e-06,
      "loss": 0.8842,
      "step": 5200
    },
    {
      "epoch": 0.8852513779856356,
      "grad_norm": 17.23415756225586,
      "learning_rate": 8.229497244028728e-06,
      "loss": 0.9137,
      "step": 5300
    },
    {
      "epoch": 0.9019542341740437,
      "grad_norm": 18.819408416748047,
      "learning_rate": 8.196091531651913e-06,
      "loss": 0.866,
      "step": 5400
    },
    {
      "epoch": 0.918657090362452,
      "grad_norm": 12.186098098754883,
      "learning_rate": 8.162685819275096e-06,
      "loss": 0.8881,
      "step": 5500
    },
    {
      "epoch": 0.9353599465508602,
      "grad_norm": 16.277429580688477,
      "learning_rate": 8.129280106898281e-06,
      "loss": 0.8622,
      "step": 5600
    },
    {
      "epoch": 0.9520628027392685,
      "grad_norm": 13.378631591796875,
      "learning_rate": 8.095874394521464e-06,
      "loss": 0.8644,
      "step": 5700
    },
    {
      "epoch": 0.9687656589276766,
      "grad_norm": 24.74076271057129,
      "learning_rate": 8.062468682144647e-06,
      "loss": 0.8702,
      "step": 5800
    },
    {
      "epoch": 0.9854685151160848,
      "grad_norm": 17.841747283935547,
      "learning_rate": 8.029062969767832e-06,
      "loss": 0.8338,
      "step": 5900
    },
    {
      "epoch": 1.002171371304493,
      "grad_norm": 20.967966079711914,
      "learning_rate": 7.995657257391015e-06,
      "loss": 0.821,
      "step": 6000
    },
    {
      "epoch": 1.0188742274929012,
      "grad_norm": 15.077567100524902,
      "learning_rate": 7.962251545014198e-06,
      "loss": 0.7081,
      "step": 6100
    },
    {
      "epoch": 1.0355770836813094,
      "grad_norm": 25.127805709838867,
      "learning_rate": 7.928845832637383e-06,
      "loss": 0.7839,
      "step": 6200
    },
    {
      "epoch": 1.0522799398697178,
      "grad_norm": 14.946002006530762,
      "learning_rate": 7.895440120260566e-06,
      "loss": 0.813,
      "step": 6300
    },
    {
      "epoch": 1.068982796058126,
      "grad_norm": 15.440951347351074,
      "learning_rate": 7.862034407883749e-06,
      "loss": 0.8031,
      "step": 6400
    },
    {
      "epoch": 1.0856856522465341,
      "grad_norm": 18.30076026916504,
      "learning_rate": 7.828628695506932e-06,
      "loss": 0.7433,
      "step": 6500
    },
    {
      "epoch": 1.1023885084349423,
      "grad_norm": 14.517585754394531,
      "learning_rate": 7.795222983130117e-06,
      "loss": 0.7444,
      "step": 6600
    },
    {
      "epoch": 1.1190913646233507,
      "grad_norm": 13.410470962524414,
      "learning_rate": 7.7618172707533e-06,
      "loss": 0.763,
      "step": 6700
    },
    {
      "epoch": 1.1357942208117588,
      "grad_norm": 12.995722770690918,
      "learning_rate": 7.728411558376483e-06,
      "loss": 0.7185,
      "step": 6800
    },
    {
      "epoch": 1.152497077000167,
      "grad_norm": 8.33368968963623,
      "learning_rate": 7.695005845999667e-06,
      "loss": 0.7036,
      "step": 6900
    },
    {
      "epoch": 1.1691999331885752,
      "grad_norm": 12.641365051269531,
      "learning_rate": 7.66160013362285e-06,
      "loss": 0.7275,
      "step": 7000
    },
    {
      "epoch": 1.1859027893769833,
      "grad_norm": 16.50495719909668,
      "learning_rate": 7.6281944212460335e-06,
      "loss": 0.7239,
      "step": 7100
    },
    {
      "epoch": 1.2026056455653917,
      "grad_norm": 19.225814819335938,
      "learning_rate": 7.594788708869217e-06,
      "loss": 0.8002,
      "step": 7200
    },
    {
      "epoch": 1.2193085017538,
      "grad_norm": 31.010705947875977,
      "learning_rate": 7.561382996492401e-06,
      "loss": 0.7932,
      "step": 7300
    },
    {
      "epoch": 1.236011357942208,
      "grad_norm": 20.961395263671875,
      "learning_rate": 7.527977284115584e-06,
      "loss": 0.778,
      "step": 7400
    },
    {
      "epoch": 1.2527142141306165,
      "grad_norm": 18.0695858001709,
      "learning_rate": 7.494571571738768e-06,
      "loss": 0.7594,
      "step": 7500
    },
    {
      "epoch": 1.2694170703190246,
      "grad_norm": 9.425049781799316,
      "learning_rate": 7.461165859361952e-06,
      "loss": 0.6057,
      "step": 7600
    },
    {
      "epoch": 1.2861199265074328,
      "grad_norm": 11.393806457519531,
      "learning_rate": 7.427760146985134e-06,
      "loss": 0.742,
      "step": 7700
    },
    {
      "epoch": 1.302822782695841,
      "grad_norm": 26.427804946899414,
      "learning_rate": 7.394354434608318e-06,
      "loss": 0.7594,
      "step": 7800
    },
    {
      "epoch": 1.3195256388842491,
      "grad_norm": 17.174579620361328,
      "learning_rate": 7.360948722231502e-06,
      "loss": 0.7633,
      "step": 7900
    },
    {
      "epoch": 1.3362284950726575,
      "grad_norm": 16.589611053466797,
      "learning_rate": 7.327543009854686e-06,
      "loss": 0.8077,
      "step": 8000
    },
    {
      "epoch": 1.3529313512610657,
      "grad_norm": 16.141286849975586,
      "learning_rate": 7.294137297477869e-06,
      "loss": 0.7486,
      "step": 8100
    },
    {
      "epoch": 1.3696342074494738,
      "grad_norm": 19.7032527923584,
      "learning_rate": 7.260731585101053e-06,
      "loss": 0.7905,
      "step": 8200
    },
    {
      "epoch": 1.386337063637882,
      "grad_norm": 15.90749740600586,
      "learning_rate": 7.227325872724237e-06,
      "loss": 0.7814,
      "step": 8300
    },
    {
      "epoch": 1.4030399198262904,
      "grad_norm": 38.58119583129883,
      "learning_rate": 7.193920160347419e-06,
      "loss": 0.7571,
      "step": 8400
    },
    {
      "epoch": 1.4197427760146986,
      "grad_norm": 13.540145874023438,
      "learning_rate": 7.160514447970603e-06,
      "loss": 0.7489,
      "step": 8500
    },
    {
      "epoch": 1.4364456322031067,
      "grad_norm": 21.602752685546875,
      "learning_rate": 7.127108735593787e-06,
      "loss": 0.6791,
      "step": 8600
    },
    {
      "epoch": 1.453148488391515,
      "grad_norm": 21.0322208404541,
      "learning_rate": 7.09370302321697e-06,
      "loss": 0.7232,
      "step": 8700
    },
    {
      "epoch": 1.469851344579923,
      "grad_norm": 21.772930145263672,
      "learning_rate": 7.060297310840154e-06,
      "loss": 0.8207,
      "step": 8800
    },
    {
      "epoch": 1.4865542007683314,
      "grad_norm": 20.14775276184082,
      "learning_rate": 7.026891598463338e-06,
      "loss": 0.7709,
      "step": 8900
    },
    {
      "epoch": 1.5032570569567396,
      "grad_norm": 19.661548614501953,
      "learning_rate": 6.993485886086522e-06,
      "loss": 0.7033,
      "step": 9000
    },
    {
      "epoch": 1.5199599131451478,
      "grad_norm": 24.86128044128418,
      "learning_rate": 6.960080173709705e-06,
      "loss": 0.7515,
      "step": 9100
    },
    {
      "epoch": 1.5366627693335562,
      "grad_norm": 11.910988807678223,
      "learning_rate": 6.926674461332889e-06,
      "loss": 0.719,
      "step": 9200
    },
    {
      "epoch": 1.5533656255219643,
      "grad_norm": 17.34714698791504,
      "learning_rate": 6.893268748956073e-06,
      "loss": 0.766,
      "step": 9300
    },
    {
      "epoch": 1.5700684817103725,
      "grad_norm": 23.10816192626953,
      "learning_rate": 6.859863036579255e-06,
      "loss": 0.7147,
      "step": 9400
    },
    {
      "epoch": 1.5867713378987807,
      "grad_norm": 10.131864547729492,
      "learning_rate": 6.826457324202439e-06,
      "loss": 0.8114,
      "step": 9500
    },
    {
      "epoch": 1.6034741940871888,
      "grad_norm": 22.92327880859375,
      "learning_rate": 6.793051611825623e-06,
      "loss": 0.7148,
      "step": 9600
    },
    {
      "epoch": 1.620177050275597,
      "grad_norm": 24.38917350769043,
      "learning_rate": 6.7596458994488065e-06,
      "loss": 0.733,
      "step": 9700
    },
    {
      "epoch": 1.6368799064640054,
      "grad_norm": 19.848031997680664,
      "learning_rate": 6.72624018707199e-06,
      "loss": 0.7549,
      "step": 9800
    },
    {
      "epoch": 1.6535827626524136,
      "grad_norm": 27.370447158813477,
      "learning_rate": 6.6928344746951735e-06,
      "loss": 0.7825,
      "step": 9900
    },
    {
      "epoch": 1.670285618840822,
      "grad_norm": 9.103065490722656,
      "learning_rate": 6.659428762318357e-06,
      "loss": 0.7997,
      "step": 10000
    },
    {
      "epoch": 1.68698847502923,
      "grad_norm": 17.75422477722168,
      "learning_rate": 6.6260230499415405e-06,
      "loss": 0.7592,
      "step": 10100
    },
    {
      "epoch": 1.7036913312176383,
      "grad_norm": 7.288029193878174,
      "learning_rate": 6.592617337564724e-06,
      "loss": 0.6897,
      "step": 10200
    },
    {
      "epoch": 1.7203941874060464,
      "grad_norm": 22.00494956970215,
      "learning_rate": 6.559211625187908e-06,
      "loss": 0.7082,
      "step": 10300
    },
    {
      "epoch": 1.7370970435944546,
      "grad_norm": 12.439621925354004,
      "learning_rate": 6.525805912811092e-06,
      "loss": 0.7689,
      "step": 10400
    },
    {
      "epoch": 1.7537998997828628,
      "grad_norm": 45.97142028808594,
      "learning_rate": 6.492400200434274e-06,
      "loss": 0.796,
      "step": 10500
    },
    {
      "epoch": 1.770502755971271,
      "grad_norm": 15.072502136230469,
      "learning_rate": 6.458994488057458e-06,
      "loss": 0.7631,
      "step": 10600
    },
    {
      "epoch": 1.7872056121596793,
      "grad_norm": 9.901058197021484,
      "learning_rate": 6.425588775680642e-06,
      "loss": 0.759,
      "step": 10700
    },
    {
      "epoch": 1.8039084683480875,
      "grad_norm": 13.078925132751465,
      "learning_rate": 6.392183063303825e-06,
      "loss": 0.7965,
      "step": 10800
    },
    {
      "epoch": 1.8206113245364959,
      "grad_norm": 16.894094467163086,
      "learning_rate": 6.358777350927009e-06,
      "loss": 0.7126,
      "step": 10900
    },
    {
      "epoch": 1.837314180724904,
      "grad_norm": 15.868441581726074,
      "learning_rate": 6.325371638550193e-06,
      "loss": 0.7292,
      "step": 11000
    },
    {
      "epoch": 1.8540170369133122,
      "grad_norm": 16.986108779907227,
      "learning_rate": 6.291965926173375e-06,
      "loss": 0.7305,
      "step": 11100
    },
    {
      "epoch": 1.8707198931017204,
      "grad_norm": 3.3281209468841553,
      "learning_rate": 6.258560213796559e-06,
      "loss": 0.7364,
      "step": 11200
    },
    {
      "epoch": 1.8874227492901285,
      "grad_norm": 25.774213790893555,
      "learning_rate": 6.225154501419743e-06,
      "loss": 0.7878,
      "step": 11300
    },
    {
      "epoch": 1.9041256054785367,
      "grad_norm": 15.142520904541016,
      "learning_rate": 6.191748789042927e-06,
      "loss": 0.75,
      "step": 11400
    },
    {
      "epoch": 1.920828461666945,
      "grad_norm": 14.219281196594238,
      "learning_rate": 6.15834307666611e-06,
      "loss": 0.7057,
      "step": 11500
    },
    {
      "epoch": 1.9375313178553533,
      "grad_norm": 11.788063049316406,
      "learning_rate": 6.124937364289294e-06,
      "loss": 0.8163,
      "step": 11600
    },
    {
      "epoch": 1.9542341740437614,
      "grad_norm": 24.658660888671875,
      "learning_rate": 6.091531651912478e-06,
      "loss": 0.8341,
      "step": 11700
    },
    {
      "epoch": 1.9709370302321698,
      "grad_norm": 9.698348999023438,
      "learning_rate": 6.058125939535661e-06,
      "loss": 0.7351,
      "step": 11800
    },
    {
      "epoch": 1.987639886420578,
      "grad_norm": 15.810676574707031,
      "learning_rate": 6.024720227158845e-06,
      "loss": 0.7752,
      "step": 11900
    },
    {
      "epoch": 2.004342742608986,
      "grad_norm": 5.613903999328613,
      "learning_rate": 5.991314514782029e-06,
      "loss": 0.7122,
      "step": 12000
    },
    {
      "epoch": 2.0210455987973943,
      "grad_norm": 16.41714859008789,
      "learning_rate": 5.957908802405213e-06,
      "loss": 0.5661,
      "step": 12100
    },
    {
      "epoch": 2.0377484549858025,
      "grad_norm": 11.582777976989746,
      "learning_rate": 5.924503090028395e-06,
      "loss": 0.59,
      "step": 12200
    },
    {
      "epoch": 2.0544513111742106,
      "grad_norm": 10.235818862915039,
      "learning_rate": 5.891097377651579e-06,
      "loss": 0.5638,
      "step": 12300
    },
    {
      "epoch": 2.071154167362619,
      "grad_norm": 19.76612091064453,
      "learning_rate": 5.857691665274763e-06,
      "loss": 0.6028,
      "step": 12400
    },
    {
      "epoch": 2.0878570235510274,
      "grad_norm": 24.748563766479492,
      "learning_rate": 5.824285952897946e-06,
      "loss": 0.6529,
      "step": 12500
    },
    {
      "epoch": 2.1045598797394356,
      "grad_norm": 29.658466339111328,
      "learning_rate": 5.79088024052113e-06,
      "loss": 0.6788,
      "step": 12600
    },
    {
      "epoch": 2.1212627359278438,
      "grad_norm": 21.23779296875,
      "learning_rate": 5.7574745281443135e-06,
      "loss": 0.5635,
      "step": 12700
    },
    {
      "epoch": 2.137965592116252,
      "grad_norm": 3.3180506229400635,
      "learning_rate": 5.724068815767497e-06,
      "loss": 0.6079,
      "step": 12800
    },
    {
      "epoch": 2.15466844830466,
      "grad_norm": 36.384910583496094,
      "learning_rate": 5.6906631033906805e-06,
      "loss": 0.6009,
      "step": 12900
    },
    {
      "epoch": 2.1713713044930683,
      "grad_norm": 29.425743103027344,
      "learning_rate": 5.6572573910138635e-06,
      "loss": 0.6103,
      "step": 13000
    },
    {
      "epoch": 2.1880741606814764,
      "grad_norm": 22.06406593322754,
      "learning_rate": 5.6238516786370474e-06,
      "loss": 0.6043,
      "step": 13100
    },
    {
      "epoch": 2.2047770168698846,
      "grad_norm": 38.30031967163086,
      "learning_rate": 5.5904459662602305e-06,
      "loss": 0.5667,
      "step": 13200
    },
    {
      "epoch": 2.2214798730582928,
      "grad_norm": 20.78784942626953,
      "learning_rate": 5.557040253883414e-06,
      "loss": 0.6424,
      "step": 13300
    },
    {
      "epoch": 2.2381827292467014,
      "grad_norm": 11.00820541381836,
      "learning_rate": 5.523634541506598e-06,
      "loss": 0.6237,
      "step": 13400
    },
    {
      "epoch": 2.2548855854351095,
      "grad_norm": 9.542475700378418,
      "learning_rate": 5.490228829129781e-06,
      "loss": 0.5489,
      "step": 13500
    },
    {
      "epoch": 2.2715884416235177,
      "grad_norm": 37.37931442260742,
      "learning_rate": 5.456823116752965e-06,
      "loss": 0.5506,
      "step": 13600
    },
    {
      "epoch": 2.288291297811926,
      "grad_norm": 31.07256317138672,
      "learning_rate": 5.423417404376149e-06,
      "loss": 0.6088,
      "step": 13700
    },
    {
      "epoch": 2.304994154000334,
      "grad_norm": 11.085986137390137,
      "learning_rate": 5.390011691999333e-06,
      "loss": 0.6323,
      "step": 13800
    },
    {
      "epoch": 2.321697010188742,
      "grad_norm": 2.0125973224639893,
      "learning_rate": 5.356605979622515e-06,
      "loss": 0.5749,
      "step": 13900
    },
    {
      "epoch": 2.3383998663771504,
      "grad_norm": 15.133343696594238,
      "learning_rate": 5.323200267245699e-06,
      "loss": 0.6595,
      "step": 14000
    },
    {
      "epoch": 2.3551027225655585,
      "grad_norm": 15.731000900268555,
      "learning_rate": 5.289794554868883e-06,
      "loss": 0.6198,
      "step": 14100
    },
    {
      "epoch": 2.3718055787539667,
      "grad_norm": 24.739046096801758,
      "learning_rate": 5.256388842492066e-06,
      "loss": 0.6252,
      "step": 14200
    },
    {
      "epoch": 2.3885084349423753,
      "grad_norm": 30.11444091796875,
      "learning_rate": 5.22298313011525e-06,
      "loss": 0.5504,
      "step": 14300
    },
    {
      "epoch": 2.4052112911307835,
      "grad_norm": 12.704254150390625,
      "learning_rate": 5.189577417738434e-06,
      "loss": 0.6514,
      "step": 14400
    },
    {
      "epoch": 2.4219141473191916,
      "grad_norm": 18.6417293548584,
      "learning_rate": 5.156171705361617e-06,
      "loss": 0.5852,
      "step": 14500
    },
    {
      "epoch": 2.4386170035076,
      "grad_norm": 24.628541946411133,
      "learning_rate": 5.122765992984801e-06,
      "loss": 0.6128,
      "step": 14600
    },
    {
      "epoch": 2.455319859696008,
      "grad_norm": 38.46048355102539,
      "learning_rate": 5.089360280607985e-06,
      "loss": 0.6127,
      "step": 14700
    },
    {
      "epoch": 2.472022715884416,
      "grad_norm": 51.973026275634766,
      "learning_rate": 5.055954568231169e-06,
      "loss": 0.6004,
      "step": 14800
    },
    {
      "epoch": 2.4887255720728243,
      "grad_norm": 19.359779357910156,
      "learning_rate": 5.022548855854351e-06,
      "loss": 0.6187,
      "step": 14900
    },
    {
      "epoch": 2.505428428261233,
      "grad_norm": 23.739988327026367,
      "learning_rate": 4.989143143477535e-06,
      "loss": 0.5553,
      "step": 15000
    },
    {
      "epoch": 2.5221312844496406,
      "grad_norm": 15.924478530883789,
      "learning_rate": 4.955737431100719e-06,
      "loss": 0.5534,
      "step": 15100
    },
    {
      "epoch": 2.5388341406380492,
      "grad_norm": 27.656553268432617,
      "learning_rate": 4.922331718723903e-06,
      "loss": 0.5793,
      "step": 15200
    },
    {
      "epoch": 2.5555369968264574,
      "grad_norm": 27.42656898498535,
      "learning_rate": 4.888926006347086e-06,
      "loss": 0.5708,
      "step": 15300
    },
    {
      "epoch": 2.5722398530148656,
      "grad_norm": 33.04301071166992,
      "learning_rate": 4.85552029397027e-06,
      "loss": 0.5942,
      "step": 15400
    },
    {
      "epoch": 2.5889427092032737,
      "grad_norm": 35.11698913574219,
      "learning_rate": 4.822114581593453e-06,
      "loss": 0.6353,
      "step": 15500
    },
    {
      "epoch": 2.605645565391682,
      "grad_norm": 19.75358772277832,
      "learning_rate": 4.788708869216637e-06,
      "loss": 0.556,
      "step": 15600
    },
    {
      "epoch": 2.62234842158009,
      "grad_norm": 43.060546875,
      "learning_rate": 4.75530315683982e-06,
      "loss": 0.5677,
      "step": 15700
    },
    {
      "epoch": 2.6390512777684982,
      "grad_norm": 25.660778045654297,
      "learning_rate": 4.7218974444630036e-06,
      "loss": 0.5388,
      "step": 15800
    },
    {
      "epoch": 2.655754133956907,
      "grad_norm": 31.610877990722656,
      "learning_rate": 4.6884917320861875e-06,
      "loss": 0.646,
      "step": 15900
    },
    {
      "epoch": 2.672456990145315,
      "grad_norm": 31.48868751525879,
      "learning_rate": 4.6550860197093705e-06,
      "loss": 0.5609,
      "step": 16000
    },
    {
      "epoch": 2.689159846333723,
      "grad_norm": 38.78115463256836,
      "learning_rate": 4.6216803073325544e-06,
      "loss": 0.6161,
      "step": 16100
    },
    {
      "epoch": 2.7058627025221313,
      "grad_norm": 20.78879737854004,
      "learning_rate": 4.5882745949557375e-06,
      "loss": 0.5929,
      "step": 16200
    },
    {
      "epoch": 2.7225655587105395,
      "grad_norm": 20.89682960510254,
      "learning_rate": 4.554868882578921e-06,
      "loss": 0.6028,
      "step": 16300
    },
    {
      "epoch": 2.7392684148989477,
      "grad_norm": 27.97114372253418,
      "learning_rate": 4.521463170202105e-06,
      "loss": 0.5945,
      "step": 16400
    },
    {
      "epoch": 2.755971271087356,
      "grad_norm": 11.90023422241211,
      "learning_rate": 4.488057457825288e-06,
      "loss": 0.6369,
      "step": 16500
    },
    {
      "epoch": 2.772674127275764,
      "grad_norm": 41.38847351074219,
      "learning_rate": 4.454651745448472e-06,
      "loss": 0.5847,
      "step": 16600
    },
    {
      "epoch": 2.789376983464172,
      "grad_norm": 18.860322952270508,
      "learning_rate": 4.421246033071655e-06,
      "loss": 0.5846,
      "step": 16700
    },
    {
      "epoch": 2.806079839652581,
      "grad_norm": 27.716350555419922,
      "learning_rate": 4.387840320694839e-06,
      "loss": 0.5945,
      "step": 16800
    },
    {
      "epoch": 2.822782695840989,
      "grad_norm": 17.139558792114258,
      "learning_rate": 4.354434608318023e-06,
      "loss": 0.6385,
      "step": 16900
    },
    {
      "epoch": 2.839485552029397,
      "grad_norm": 17.07324981689453,
      "learning_rate": 4.321028895941206e-06,
      "loss": 0.6203,
      "step": 17000
    },
    {
      "epoch": 2.8561884082178053,
      "grad_norm": 30.65843391418457,
      "learning_rate": 4.28762318356439e-06,
      "loss": 0.6161,
      "step": 17100
    },
    {
      "epoch": 2.8728912644062135,
      "grad_norm": 24.91840362548828,
      "learning_rate": 4.254217471187573e-06,
      "loss": 0.5894,
      "step": 17200
    },
    {
      "epoch": 2.8895941205946216,
      "grad_norm": 28.003055572509766,
      "learning_rate": 4.220811758810757e-06,
      "loss": 0.608,
      "step": 17300
    },
    {
      "epoch": 2.90629697678303,
      "grad_norm": 13.411645889282227,
      "learning_rate": 4.187406046433941e-06,
      "loss": 0.5611,
      "step": 17400
    },
    {
      "epoch": 2.922999832971438,
      "grad_norm": 28.59213638305664,
      "learning_rate": 4.154000334057124e-06,
      "loss": 0.6002,
      "step": 17500
    },
    {
      "epoch": 2.939702689159846,
      "grad_norm": 23.29584503173828,
      "learning_rate": 4.120594621680308e-06,
      "loss": 0.5511,
      "step": 17600
    },
    {
      "epoch": 2.9564055453482547,
      "grad_norm": 32.18936538696289,
      "learning_rate": 4.087188909303491e-06,
      "loss": 0.5975,
      "step": 17700
    },
    {
      "epoch": 2.973108401536663,
      "grad_norm": 30.644224166870117,
      "learning_rate": 4.053783196926675e-06,
      "loss": 0.5662,
      "step": 17800
    },
    {
      "epoch": 2.989811257725071,
      "grad_norm": 23.414264678955078,
      "learning_rate": 4.020377484549858e-06,
      "loss": 0.5177,
      "step": 17900
    },
    {
      "epoch": 3.0065141139134792,
      "grad_norm": 50.97584915161133,
      "learning_rate": 3.986971772173042e-06,
      "loss": 0.524,
      "step": 18000
    },
    {
      "epoch": 3.0232169701018874,
      "grad_norm": 21.676570892333984,
      "learning_rate": 3.953566059796226e-06,
      "loss": 0.4479,
      "step": 18100
    },
    {
      "epoch": 3.0399198262902956,
      "grad_norm": 2.8428845405578613,
      "learning_rate": 3.920160347419409e-06,
      "loss": 0.4272,
      "step": 18200
    },
    {
      "epoch": 3.0566226824787037,
      "grad_norm": 26.6216983795166,
      "learning_rate": 3.886754635042593e-06,
      "loss": 0.4339,
      "step": 18300
    },
    {
      "epoch": 3.073325538667112,
      "grad_norm": 57.29806137084961,
      "learning_rate": 3.853348922665776e-06,
      "loss": 0.4327,
      "step": 18400
    },
    {
      "epoch": 3.0900283948555205,
      "grad_norm": 8.64271068572998,
      "learning_rate": 3.81994321028896e-06,
      "loss": 0.3777,
      "step": 18500
    },
    {
      "epoch": 3.1067312510439287,
      "grad_norm": 5.349540710449219,
      "learning_rate": 3.786537497912143e-06,
      "loss": 0.4667,
      "step": 18600
    },
    {
      "epoch": 3.123434107232337,
      "grad_norm": 37.47409439086914,
      "learning_rate": 3.7531317855353266e-06,
      "loss": 0.4699,
      "step": 18700
    },
    {
      "epoch": 3.140136963420745,
      "grad_norm": 51.3149299621582,
      "learning_rate": 3.7197260731585105e-06,
      "loss": 0.4712,
      "step": 18800
    },
    {
      "epoch": 3.156839819609153,
      "grad_norm": 39.72975540161133,
      "learning_rate": 3.686320360781694e-06,
      "loss": 0.4814,
      "step": 18900
    },
    {
      "epoch": 3.1735426757975613,
      "grad_norm": 50.40065383911133,
      "learning_rate": 3.652914648404878e-06,
      "loss": 0.4616,
      "step": 19000
    },
    {
      "epoch": 3.1902455319859695,
      "grad_norm": 46.605987548828125,
      "learning_rate": 3.619508936028061e-06,
      "loss": 0.4639,
      "step": 19100
    },
    {
      "epoch": 3.2069483881743777,
      "grad_norm": 71.9764175415039,
      "learning_rate": 3.5861032236512445e-06,
      "loss": 0.4512,
      "step": 19200
    },
    {
      "epoch": 3.2236512443627863,
      "grad_norm": 45.87346267700195,
      "learning_rate": 3.5526975112744284e-06,
      "loss": 0.4466,
      "step": 19300
    },
    {
      "epoch": 3.2403541005511944,
      "grad_norm": 14.463725090026855,
      "learning_rate": 3.5192917988976114e-06,
      "loss": 0.4441,
      "step": 19400
    },
    {
      "epoch": 3.2570569567396026,
      "grad_norm": 45.183101654052734,
      "learning_rate": 3.4858860865207953e-06,
      "loss": 0.5395,
      "step": 19500
    },
    {
      "epoch": 3.2737598129280108,
      "grad_norm": 6.893800735473633,
      "learning_rate": 3.452480374143979e-06,
      "loss": 0.4382,
      "step": 19600
    },
    {
      "epoch": 3.290462669116419,
      "grad_norm": 29.887908935546875,
      "learning_rate": 3.4190746617671627e-06,
      "loss": 0.4517,
      "step": 19700
    },
    {
      "epoch": 3.307165525304827,
      "grad_norm": 28.874895095825195,
      "learning_rate": 3.385668949390346e-06,
      "loss": 0.4485,
      "step": 19800
    },
    {
      "epoch": 3.3238683814932353,
      "grad_norm": 21.24345588684082,
      "learning_rate": 3.3522632370135293e-06,
      "loss": 0.4843,
      "step": 19900
    },
    {
      "epoch": 3.3405712376816434,
      "grad_norm": 74.26712799072266,
      "learning_rate": 3.318857524636713e-06,
      "loss": 0.4659,
      "step": 20000
    },
    {
      "epoch": 3.3572740938700516,
      "grad_norm": 25.51314353942871,
      "learning_rate": 3.2854518122598966e-06,
      "loss": 0.4621,
      "step": 20100
    },
    {
      "epoch": 3.37397695005846,
      "grad_norm": 50.74665069580078,
      "learning_rate": 3.2520460998830805e-06,
      "loss": 0.4832,
      "step": 20200
    },
    {
      "epoch": 3.3906798062468684,
      "grad_norm": 5.766060829162598,
      "learning_rate": 3.218640387506264e-06,
      "loss": 0.4813,
      "step": 20300
    },
    {
      "epoch": 3.4073826624352765,
      "grad_norm": 26.709684371948242,
      "learning_rate": 3.185234675129447e-06,
      "loss": 0.4026,
      "step": 20400
    },
    {
      "epoch": 3.4240855186236847,
      "grad_norm": 15.361512184143066,
      "learning_rate": 3.151828962752631e-06,
      "loss": 0.4296,
      "step": 20500
    },
    {
      "epoch": 3.440788374812093,
      "grad_norm": 52.27903366088867,
      "learning_rate": 3.1184232503758145e-06,
      "loss": 0.4341,
      "step": 20600
    },
    {
      "epoch": 3.457491231000501,
      "grad_norm": 29.5826473236084,
      "learning_rate": 3.0850175379989984e-06,
      "loss": 0.4862,
      "step": 20700
    },
    {
      "epoch": 3.474194087188909,
      "grad_norm": 22.63140296936035,
      "learning_rate": 3.0516118256221814e-06,
      "loss": 0.4554,
      "step": 20800
    },
    {
      "epoch": 3.4908969433773174,
      "grad_norm": 34.95733642578125,
      "learning_rate": 3.018206113245365e-06,
      "loss": 0.4061,
      "step": 20900
    },
    {
      "epoch": 3.5075997995657255,
      "grad_norm": 32.50165557861328,
      "learning_rate": 2.984800400868549e-06,
      "loss": 0.5343,
      "step": 21000
    },
    {
      "epoch": 3.524302655754134,
      "grad_norm": 10.328845977783203,
      "learning_rate": 2.9513946884917323e-06,
      "loss": 0.409,
      "step": 21100
    },
    {
      "epoch": 3.5410055119425423,
      "grad_norm": 17.831979751586914,
      "learning_rate": 2.917988976114916e-06,
      "loss": 0.4278,
      "step": 21200
    },
    {
      "epoch": 3.5577083681309505,
      "grad_norm": 20.61768913269043,
      "learning_rate": 2.8845832637380993e-06,
      "loss": 0.4191,
      "step": 21300
    },
    {
      "epoch": 3.5744112243193586,
      "grad_norm": 21.616174697875977,
      "learning_rate": 2.851177551361283e-06,
      "loss": 0.442,
      "step": 21400
    },
    {
      "epoch": 3.591114080507767,
      "grad_norm": 40.32358169555664,
      "learning_rate": 2.8177718389844666e-06,
      "loss": 0.4244,
      "step": 21500
    },
    {
      "epoch": 3.607816936696175,
      "grad_norm": 13.252115249633789,
      "learning_rate": 2.78436612660765e-06,
      "loss": 0.4396,
      "step": 21600
    },
    {
      "epoch": 3.624519792884583,
      "grad_norm": 43.478057861328125,
      "learning_rate": 2.7509604142308336e-06,
      "loss": 0.4343,
      "step": 21700
    },
    {
      "epoch": 3.6412226490729918,
      "grad_norm": 29.63460922241211,
      "learning_rate": 2.717554701854017e-06,
      "loss": 0.4087,
      "step": 21800
    },
    {
      "epoch": 3.6579255052613995,
      "grad_norm": 60.217063903808594,
      "learning_rate": 2.684148989477201e-06,
      "loss": 0.5167,
      "step": 21900
    },
    {
      "epoch": 3.674628361449808,
      "grad_norm": 44.48373794555664,
      "learning_rate": 2.6507432771003845e-06,
      "loss": 0.4692,
      "step": 22000
    },
    {
      "epoch": 3.6913312176382163,
      "grad_norm": 65.64668273925781,
      "learning_rate": 2.6173375647235675e-06,
      "loss": 0.4935,
      "step": 22100
    },
    {
      "epoch": 3.7080340738266244,
      "grad_norm": 35.08185577392578,
      "learning_rate": 2.5839318523467514e-06,
      "loss": 0.4585,
      "step": 22200
    },
    {
      "epoch": 3.7247369300150326,
      "grad_norm": 20.25369644165039,
      "learning_rate": 2.550526139969935e-06,
      "loss": 0.5243,
      "step": 22300
    },
    {
      "epoch": 3.7414397862034408,
      "grad_norm": 47.03718185424805,
      "learning_rate": 2.517120427593119e-06,
      "loss": 0.5132,
      "step": 22400
    },
    {
      "epoch": 3.758142642391849,
      "grad_norm": 57.298309326171875,
      "learning_rate": 2.4837147152163023e-06,
      "loss": 0.4692,
      "step": 22500
    },
    {
      "epoch": 3.774845498580257,
      "grad_norm": 10.650708198547363,
      "learning_rate": 2.4503090028394858e-06,
      "loss": 0.3936,
      "step": 22600
    },
    {
      "epoch": 3.7915483547686657,
      "grad_norm": 57.70272445678711,
      "learning_rate": 2.4169032904626693e-06,
      "loss": 0.4558,
      "step": 22700
    },
    {
      "epoch": 3.8082512109570734,
      "grad_norm": 26.080385208129883,
      "learning_rate": 2.383497578085853e-06,
      "loss": 0.5072,
      "step": 22800
    },
    {
      "epoch": 3.824954067145482,
      "grad_norm": 29.37761878967285,
      "learning_rate": 2.3500918657090362e-06,
      "loss": 0.5186,
      "step": 22900
    },
    {
      "epoch": 3.84165692333389,
      "grad_norm": 73.6252212524414,
      "learning_rate": 2.3166861533322197e-06,
      "loss": 0.4156,
      "step": 23000
    },
    {
      "epoch": 3.8583597795222984,
      "grad_norm": 34.31514358520508,
      "learning_rate": 2.2832804409554036e-06,
      "loss": 0.4675,
      "step": 23100
    },
    {
      "epoch": 3.8750626357107065,
      "grad_norm": 48.847816467285156,
      "learning_rate": 2.249874728578587e-06,
      "loss": 0.5029,
      "step": 23200
    },
    {
      "epoch": 3.8917654918991147,
      "grad_norm": 56.990135192871094,
      "learning_rate": 2.2164690162017706e-06,
      "loss": 0.472,
      "step": 23300
    },
    {
      "epoch": 3.908468348087523,
      "grad_norm": 46.1951904296875,
      "learning_rate": 2.1830633038249545e-06,
      "loss": 0.4641,
      "step": 23400
    },
    {
      "epoch": 3.925171204275931,
      "grad_norm": 47.443660736083984,
      "learning_rate": 2.1496575914481375e-06,
      "loss": 0.4429,
      "step": 23500
    },
    {
      "epoch": 3.9418740604643396,
      "grad_norm": 43.62672424316406,
      "learning_rate": 2.1162518790713214e-06,
      "loss": 0.4573,
      "step": 23600
    },
    {
      "epoch": 3.9585769166527474,
      "grad_norm": 19.36794662475586,
      "learning_rate": 2.082846166694505e-06,
      "loss": 0.4625,
      "step": 23700
    },
    {
      "epoch": 3.975279772841156,
      "grad_norm": 80.7060546875,
      "learning_rate": 2.0494404543176884e-06,
      "loss": 0.4931,
      "step": 23800
    },
    {
      "epoch": 3.991982629029564,
      "grad_norm": 22.505474090576172,
      "learning_rate": 2.0160347419408723e-06,
      "loss": 0.3841,
      "step": 23900
    },
    {
      "epoch": 4.008685485217972,
      "grad_norm": 17.126422882080078,
      "learning_rate": 1.982629029564056e-06,
      "loss": 0.3806,
      "step": 24000
    },
    {
      "epoch": 4.025388341406381,
      "grad_norm": 1.5570582151412964,
      "learning_rate": 1.949223317187239e-06,
      "loss": 0.3095,
      "step": 24100
    },
    {
      "epoch": 4.042091197594789,
      "grad_norm": 13.739920616149902,
      "learning_rate": 1.9158176048104228e-06,
      "loss": 0.3089,
      "step": 24200
    },
    {
      "epoch": 4.058794053783197,
      "grad_norm": 0.1968810260295868,
      "learning_rate": 1.8824118924336062e-06,
      "loss": 0.3428,
      "step": 24300
    },
    {
      "epoch": 4.075496909971605,
      "grad_norm": 76.81122589111328,
      "learning_rate": 1.84900618005679e-06,
      "loss": 0.3316,
      "step": 24400
    },
    {
      "epoch": 4.092199766160014,
      "grad_norm": 25.549631118774414,
      "learning_rate": 1.8156004676799734e-06,
      "loss": 0.375,
      "step": 24500
    },
    {
      "epoch": 4.108902622348421,
      "grad_norm": 13.73573112487793,
      "learning_rate": 1.782194755303157e-06,
      "loss": 0.3604,
      "step": 24600
    },
    {
      "epoch": 4.12560547853683,
      "grad_norm": 38.51688766479492,
      "learning_rate": 1.7487890429263404e-06,
      "loss": 0.3782,
      "step": 24700
    },
    {
      "epoch": 4.142308334725238,
      "grad_norm": 75.05541229248047,
      "learning_rate": 1.715383330549524e-06,
      "loss": 0.2884,
      "step": 24800
    },
    {
      "epoch": 4.159011190913646,
      "grad_norm": 25.28105926513672,
      "learning_rate": 1.6819776181727078e-06,
      "loss": 0.3529,
      "step": 24900
    },
    {
      "epoch": 4.175714047102055,
      "grad_norm": 7.243852138519287,
      "learning_rate": 1.6485719057958912e-06,
      "loss": 0.4244,
      "step": 25000
    },
    {
      "epoch": 4.192416903290463,
      "grad_norm": 19.038829803466797,
      "learning_rate": 1.615166193419075e-06,
      "loss": 0.3354,
      "step": 25100
    },
    {
      "epoch": 4.209119759478871,
      "grad_norm": 99.81770324707031,
      "learning_rate": 1.5817604810422584e-06,
      "loss": 0.329,
      "step": 25200
    },
    {
      "epoch": 4.225822615667279,
      "grad_norm": 64.41572570800781,
      "learning_rate": 1.548354768665442e-06,
      "loss": 0.351,
      "step": 25300
    },
    {
      "epoch": 4.2425254718556875,
      "grad_norm": 82.21743774414062,
      "learning_rate": 1.5149490562886254e-06,
      "loss": 0.3568,
      "step": 25400
    },
    {
      "epoch": 4.259228328044095,
      "grad_norm": 78.22673797607422,
      "learning_rate": 1.481543343911809e-06,
      "loss": 0.3747,
      "step": 25500
    },
    {
      "epoch": 4.275931184232504,
      "grad_norm": 32.09770965576172,
      "learning_rate": 1.4481376315349926e-06,
      "loss": 0.3801,
      "step": 25600
    },
    {
      "epoch": 4.292634040420912,
      "grad_norm": 34.33573913574219,
      "learning_rate": 1.4147319191581762e-06,
      "loss": 0.3709,
      "step": 25700
    },
    {
      "epoch": 4.30933689660932,
      "grad_norm": 73.70283508300781,
      "learning_rate": 1.3813262067813595e-06,
      "loss": 0.3245,
      "step": 25800
    },
    {
      "epoch": 4.326039752797729,
      "grad_norm": 27.29327964782715,
      "learning_rate": 1.3479204944045432e-06,
      "loss": 0.359,
      "step": 25900
    },
    {
      "epoch": 4.3427426089861365,
      "grad_norm": 3.4816336631774902,
      "learning_rate": 1.314514782027727e-06,
      "loss": 0.3701,
      "step": 26000
    },
    {
      "epoch": 4.359445465174545,
      "grad_norm": 34.213199615478516,
      "learning_rate": 1.2811090696509104e-06,
      "loss": 0.3631,
      "step": 26100
    },
    {
      "epoch": 4.376148321362953,
      "grad_norm": 12.200721740722656,
      "learning_rate": 1.247703357274094e-06,
      "loss": 0.3252,
      "step": 26200
    },
    {
      "epoch": 4.3928511775513615,
      "grad_norm": 20.379730224609375,
      "learning_rate": 1.2142976448972776e-06,
      "loss": 0.3143,
      "step": 26300
    },
    {
      "epoch": 4.409554033739769,
      "grad_norm": 44.0316276550293,
      "learning_rate": 1.180891932520461e-06,
      "loss": 0.3161,
      "step": 26400
    },
    {
      "epoch": 4.426256889928178,
      "grad_norm": 59.236183166503906,
      "learning_rate": 1.1474862201436447e-06,
      "loss": 0.3902,
      "step": 26500
    },
    {
      "epoch": 4.4429597461165855,
      "grad_norm": 11.041303634643555,
      "learning_rate": 1.1140805077668282e-06,
      "loss": 0.3431,
      "step": 26600
    },
    {
      "epoch": 4.459662602304994,
      "grad_norm": 7.1995697021484375,
      "learning_rate": 1.080674795390012e-06,
      "loss": 0.3213,
      "step": 26700
    },
    {
      "epoch": 4.476365458493403,
      "grad_norm": 31.028432846069336,
      "learning_rate": 1.0472690830131954e-06,
      "loss": 0.4169,
      "step": 26800
    },
    {
      "epoch": 4.4930683146818104,
      "grad_norm": 127.18058776855469,
      "learning_rate": 1.0138633706363789e-06,
      "loss": 0.4154,
      "step": 26900
    },
    {
      "epoch": 4.509771170870219,
      "grad_norm": 43.38653564453125,
      "learning_rate": 9.804576582595626e-07,
      "loss": 0.2661,
      "step": 27000
    },
    {
      "epoch": 4.526474027058627,
      "grad_norm": 43.74714279174805,
      "learning_rate": 9.470519458827459e-07,
      "loss": 0.3784,
      "step": 27100
    },
    {
      "epoch": 4.543176883247035,
      "grad_norm": 42.56804275512695,
      "learning_rate": 9.136462335059295e-07,
      "loss": 0.3189,
      "step": 27200
    },
    {
      "epoch": 4.559879739435443,
      "grad_norm": 6.014068603515625,
      "learning_rate": 8.802405211291132e-07,
      "loss": 0.3847,
      "step": 27300
    },
    {
      "epoch": 4.576582595623852,
      "grad_norm": 115.78690338134766,
      "learning_rate": 8.468348087522967e-07,
      "loss": 0.3149,
      "step": 27400
    },
    {
      "epoch": 4.59328545181226,
      "grad_norm": 4.817471981048584,
      "learning_rate": 8.134290963754803e-07,
      "loss": 0.3497,
      "step": 27500
    },
    {
      "epoch": 4.609988308000668,
      "grad_norm": 54.96129608154297,
      "learning_rate": 7.800233839986639e-07,
      "loss": 0.2934,
      "step": 27600
    },
    {
      "epoch": 4.626691164189077,
      "grad_norm": 6.626304626464844,
      "learning_rate": 7.466176716218474e-07,
      "loss": 0.3308,
      "step": 27700
    },
    {
      "epoch": 4.643394020377484,
      "grad_norm": 57.26985168457031,
      "learning_rate": 7.132119592450309e-07,
      "loss": 0.4107,
      "step": 27800
    },
    {
      "epoch": 4.660096876565893,
      "grad_norm": 36.57368087768555,
      "learning_rate": 6.798062468682145e-07,
      "loss": 0.3331,
      "step": 27900
    },
    {
      "epoch": 4.676799732754301,
      "grad_norm": 0.8243289589881897,
      "learning_rate": 6.46400534491398e-07,
      "loss": 0.3723,
      "step": 28000
    },
    {
      "epoch": 4.693502588942709,
      "grad_norm": 53.57279968261719,
      "learning_rate": 6.129948221145816e-07,
      "loss": 0.3497,
      "step": 28100
    },
    {
      "epoch": 4.710205445131117,
      "grad_norm": 34.093074798583984,
      "learning_rate": 5.795891097377652e-07,
      "loss": 0.3043,
      "step": 28200
    },
    {
      "epoch": 4.726908301319526,
      "grad_norm": 107.15381622314453,
      "learning_rate": 5.461833973609488e-07,
      "loss": 0.3905,
      "step": 28300
    },
    {
      "epoch": 4.743611157507933,
      "grad_norm": 14.685422897338867,
      "learning_rate": 5.127776849841324e-07,
      "loss": 0.3152,
      "step": 28400
    },
    {
      "epoch": 4.760314013696342,
      "grad_norm": 13.886685371398926,
      "learning_rate": 4.793719726073158e-07,
      "loss": 0.3333,
      "step": 28500
    },
    {
      "epoch": 4.777016869884751,
      "grad_norm": 52.29263687133789,
      "learning_rate": 4.459662602304995e-07,
      "loss": 0.3093,
      "step": 28600
    },
    {
      "epoch": 4.793719726073158,
      "grad_norm": 4.412121772766113,
      "learning_rate": 4.12560547853683e-07,
      "loss": 0.4277,
      "step": 28700
    },
    {
      "epoch": 4.810422582261567,
      "grad_norm": 70.59353637695312,
      "learning_rate": 3.7915483547686655e-07,
      "loss": 0.4134,
      "step": 28800
    },
    {
      "epoch": 4.827125438449975,
      "grad_norm": 10.014254570007324,
      "learning_rate": 3.457491231000502e-07,
      "loss": 0.294,
      "step": 28900
    },
    {
      "epoch": 4.843828294638383,
      "grad_norm": 32.77077865600586,
      "learning_rate": 3.123434107232337e-07,
      "loss": 0.3727,
      "step": 29000
    }
  ],
  "logging_steps": 100,
  "max_steps": 29935,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "total_flos": 4.053536844815462e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
